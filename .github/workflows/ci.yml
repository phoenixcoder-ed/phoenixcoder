name: PhoenixCoder CI/CD Pipeline

# è§¦å‘æ¡ä»¶
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œå®Œæ•´æµ‹è¯•
    - cron: '0 2 * * *'

# ç¯å¢ƒå˜é‡
env:
  NODE_VERSION: '24'
  PYTHON_VERSION: '3.13'
  PNPM_VERSION: '9'
  POSTGRES_VERSION: '16'
  REDIS_VERSION: '7-alpine'
  # ç¼“å­˜é…ç½®
  CACHE_VERSION: 'v1'
  PNPM_CACHE_FOLDER: '.pnpm'
  PIP_CACHE_DIR: '.pip-cache'

# å¹¶å‘æ§åˆ¶
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Monorepo ä¾èµ–æ£€æŸ¥
  monorepo-deps:
    name: Monorepo ä¾èµ–æ£€æŸ¥
    runs-on: ubuntu-latest

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
          cache-dependency-path: '**/pnpm-lock.yaml'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
          run_install: false

      - name: éªŒè¯workspaceé…ç½®
        run: |
          echo "éªŒè¯pnpm workspaceé…ç½®..."
          pnpm list --depth=0 --json > workspace-info.json

          # æ£€æŸ¥workspaceç»“æ„
          echo "Workspace packages:"
          pnpm list --depth=0

          # éªŒè¯ä¾èµ–å…³ç³»
          echo "æ£€æŸ¥å†…éƒ¨ä¾èµ–å…³ç³»..."
          pnpm why @phoenixcoder/shared-types || true
          pnpm why @phoenixcoder/shared-utils || true

          # æ£€æŸ¥é‡å¤ä¾èµ–
          echo "æ£€æŸ¥é‡å¤ä¾èµ–..."
          pnpm list --depth=Infinity --json | jq '.dependencies | keys[]' | sort | uniq -d || true

      - name: æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬ä¸€è‡´æ€§
        run: |
          echo "æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬ä¸€è‡´æ€§..."

          # ä½¿ç”¨syncpackæ£€æŸ¥ç‰ˆæœ¬ä¸€è‡´æ€§
          npx syncpack list-mismatches || true

          # æ£€æŸ¥å…³é”®ä¾èµ–çš„ç‰ˆæœ¬ä¸€è‡´æ€§
          echo "æ£€æŸ¥å…³é”®ä¾èµ–ç‰ˆæœ¬:"
          find . -name "package.json" -not -path "./node_modules/*" -exec echo "=== {} ===" \; -exec jq '.dependencies.react, .dependencies."@types/react", .dependencies.typescript' {} \; 2>/dev/null || true

      - name: éªŒè¯æ„å»ºé¡ºåº
        run: |
          echo "éªŒè¯æ„å»ºé¡ºåº..."

          # æ£€æŸ¥shared packagesæ˜¯å¦å¯ä»¥ç‹¬ç«‹æ„å»º
          echo "æ„å»ºshared packages..."
          pnpm --filter="@phoenixcoder/shared-*" run build || echo "æŸäº›shared packagesæ„å»ºå¤±è´¥"

          # æ£€æŸ¥ä¾èµ–å›¾
          echo "ç”Ÿæˆä¾èµ–å›¾..."
          pnpm list --depth=Infinity --json > dependency-graph.json

      - name: ä¸Šä¼ workspaceä¿¡æ¯
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: workspace-info
          path: |
            workspace-info.json
            dependency-graph.json

  # ä»£ç è´¨é‡æ£€æŸ¥
  code-quality:
    name: ä»£ç è´¨é‡æ£€æŸ¥
    runs-on: ubuntu-latest
    needs: [monorepo-deps]

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: '**/requirements*.txt'

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
          cache-dependency-path: '**/pnpm-lock.yaml'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
          run_install: false

      - name: è·å–pnpm storeç›®å½•
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: ç¼“å­˜pnpm store
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ env.CACHE_VERSION }}-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pnpm-store-

      - name: ç¼“å­˜Pythonä¾èµ–
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ${{ env.PIP_CACHE_DIR }}
          key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pip-

      - name: ç¼“å­˜pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: ${{ runner.os }}-pre-commit-${{ env.CACHE_VERSION }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pre-commit-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pre-commit-

      - name: å®‰è£…ä¾èµ–
        run: |
          # Pythonä¾èµ–
          python -m pip install --upgrade pip
          pip install pre-commit black isort flake8 bandit mypy

          # å®‰è£…workspaceä¾èµ–
          pnpm install --frozen-lockfile

      - name: Workspaceçº§åˆ«ä»£ç æ£€æŸ¥
        run: |
          echo "è¿è¡Œworkspaceçº§åˆ«çš„ä»£ç æ£€æŸ¥..."

          # è¿è¡Œæ‰€æœ‰workspaceçš„lint
          pnpm run lint || echo "æŸäº›workspace lintå¤±è´¥"

          # æ£€æŸ¥TypeScripté…ç½®ä¸€è‡´æ€§
          echo "æ£€æŸ¥TypeScripté…ç½®..."
          find . -name "tsconfig.json" -not -path "./node_modules/*" -exec echo "=== {} ===" \; -exec cat {} \;

      - name: è¿è¡Œpre-commitæ£€æŸ¥
        run: |
          pre-commit install
          pre-commit run --all-files

      - name: ä»£ç å¤æ‚åº¦æ£€æŸ¥
        run: |
          pip install radon
          radon cc --min=C apps/community/server apps/community/oidc-server

      - name: Pythonä¾èµ–å®‰å…¨æ‰«æ (Safety)
        run: |
          pip install safety
          safety check --json --output safety-report.json || true
          safety check --short-report || true

      - name: Pythonä»£ç å®‰å…¨æ‰«æ (Bandit)
        run: |
          pip install bandit[toml]
          bandit -r apps/community/server apps/community/oidc-server \
            -f json -o bandit-report.json || true
          bandit -r apps/community/server apps/community/oidc-server \
            -f txt || true

      - name: Secretsæ‰«æ (TruffleHog)
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: main
          head: HEAD
          extra_args: --debug --only-verified

      - name: ä»£ç å®‰å…¨æ‰«æ (Semgrep)
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/secrets
            p/python
            p/javascript
            p/typescript
            p/docker
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}

      - name: è®¸å¯è¯åˆè§„æ£€æŸ¥
        run: |
          pip install pip-licenses
          pip-licenses --format=json --output-file=licenses-report.json
          pip-licenses --format=plain-vertical

          # æ£€æŸ¥ç¦ç”¨çš„è®¸å¯è¯
          python -c "
          import json

          # å®šä¹‰ç¦ç”¨çš„è®¸å¯è¯ç±»å‹
          forbidden_licenses = ['GPL-3.0', 'AGPL-3.0', 'LGPL-3.0']

          with open('licenses-report.json') as f:
              licenses = json.load(f)

          violations = []
          for pkg in licenses:
              license_name = pkg.get('License', 'Unknown')
              if any(forbidden in license_name for forbidden in forbidden_licenses):
                  violations.append(f'{pkg[\"Name\"]} ({license_name})')

          if violations:
              print('âŒ License violations found:')
              for violation in violations:
                  print(f'  - {violation}')
              exit(1)
          else:
              print('âœ… No license violations found')
          "

      - name: ä¸Šä¼ å®‰å…¨æŠ¥å‘Š
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-reports
          path: |
            safety-report.json
            bandit-report.json
            licenses-report.json

  # åç«¯æµ‹è¯•
  backend-tests:
    name: åç«¯æµ‹è¯• - ${{ matrix.service }}
    runs-on: ubuntu-latest
    needs: [code-quality, monorepo-deps]

    strategy:
      matrix:
        service: [community, enterprise]
      fail-fast: false  # å…è®¸ä¸€ä¸ªæœåŠ¡å¤±è´¥æ—¶ç»§ç»­æµ‹è¯•å…¶ä»–æœåŠ¡

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'apps/${{ matrix.service }}/server/requirements*.txt'

      - name: è®¾ç½®Node.jsç¯å¢ƒ (ç”¨äºshared packages)
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
          cache-dependency-path: '**/pnpm-lock.yaml'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
          run_install: false

      - name: æ„å»ºshared packages
        run: |
          echo "æ„å»ºshared packages..."
          pnpm install --frozen-lockfile
          pnpm --filter="@phoenixcoder/shared-*" run build || echo "æŸäº›shared packagesæ„å»ºå¤±è´¥"

      - name: å®‰è£…Pythonä¾èµ–
        working-directory: apps/${{ matrix.service }}/server
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: éªŒè¯æœåŠ¡é…ç½®
        working-directory: apps/${{ matrix.service }}/server
        run: |
          echo "éªŒè¯ ${{ matrix.service }} æœåŠ¡é…ç½®..."

          # æ£€æŸ¥é…ç½®æ–‡ä»¶
          if [ -f "config.py" ]; then
            echo "é…ç½®æ–‡ä»¶å­˜åœ¨"
          fi

          # æ£€æŸ¥æ•°æ®åº“è¿æ¥
          python -c "import psycopg2; conn = psycopg2.connect('postgresql://postgres:postgres@localhost:5432/test_db'); print('æ•°æ®åº“è¿æ¥æˆåŠŸ'); conn.close()"

          # æ£€æŸ¥Redisè¿æ¥
          python -c "import redis; r = redis.Redis(host='localhost', port=6379, db=0); r.ping(); print('Redisè¿æ¥æˆåŠŸ')"

      - name: è¿è¡Œå•å…ƒæµ‹è¯•
        working-directory: apps/${{ matrix.service }}/server
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          ENVIRONMENT: test
          SERVICE_NAME: ${{ matrix.service }}
        run: |
          # è¿è¡Œå•å…ƒæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
          python -m pytest tests/ -v \
            --cov=. \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term \
            --cov-report=json \
            --cov-fail-under=80 \
            --cov-branch \
            --junitxml=test-results.xml \
            --tb=short

          # æ£€æŸ¥è¦†ç›–ç‡é˜ˆå€¼
          python -c "
          import json
          with open('coverage.json') as f:
              data = json.load(f)
          line_coverage = data['totals']['percent_covered']
          branch_coverage = data['totals']['percent_covered_display']
          print(f'[${{ matrix.service }}] è¡Œè¦†ç›–ç‡: {line_coverage}%')
          print(f'[${{ matrix.service }}] åˆ†æ”¯è¦†ç›–ç‡: {branch_coverage}%')
          if line_coverage < 80:
              raise Exception(f'[${{ matrix.service }}] è¡Œè¦†ç›–ç‡ {line_coverage}% ä½äºè¦æ±‚çš„ 80%')
          if float(branch_coverage.rstrip('%')) < 70:
              raise Exception(f'[${{ matrix.service }}] åˆ†æ”¯è¦†ç›–ç‡ {branch_coverage} ä½äºè¦æ±‚çš„ 70%')
          "

      - name: è¿è¡Œæ€§èƒ½æµ‹è¯•
        working-directory: apps/${{ matrix.service }}/server
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          ENVIRONMENT: test
          SERVICE_NAME: ${{ matrix.service }}
        run: |
          python -m pytest tests/performance/ -v --benchmark-only --benchmark-json=benchmark-results.json || true

      - name: ä¸Šä¼ è¦†ç›–ç‡æŠ¥å‘Š
        uses: codecov/codecov-action@v3
        with:
          file: apps/${{ matrix.service }}/server/coverage.xml
          flags: backend-${{ matrix.service }}
          name: backend-${{ matrix.service }}-coverage
          fail_ci_if_error: false

      - name: ä¸Šä¼ æµ‹è¯•ç»“æœ
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: backend-test-results-${{ matrix.service }}
          path: |
            apps/${{ matrix.service }}/server/test-results.xml
            apps/${{ matrix.service }}/server/htmlcov/
            apps/${{ matrix.service }}/server/coverage.json
            apps/${{ matrix.service }}/server/benchmark-results.json

  # å‰ç«¯æµ‹è¯•
  frontend-tests:
    name: å‰ç«¯æµ‹è¯• - ${{ matrix.app }}
    runs-on: ubuntu-latest
    needs: [code-quality, monorepo-deps]

    strategy:
      matrix:
        app: [admin, miniapp]
      fail-fast: false  # å…è®¸ä¸€ä¸ªåº”ç”¨å¤±è´¥æ—¶ç»§ç»­æµ‹è¯•å…¶ä»–åº”ç”¨

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
          cache-dependency-path: '**/pnpm-lock.yaml'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
          run_install: false

      - name: è·å–pnpm storeç›®å½•
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: ç¼“å­˜pnpm store
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ env.CACHE_VERSION }}-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pnpm-store-

      - name: ç¼“å­˜æ„å»ºäº§ç‰©
        uses: actions/cache@v4
        with:
          path: |
            apps/community/${{ matrix.app }}/dist
            apps/community/${{ matrix.app }}/.vite
            apps/community/${{ matrix.app }}/node_modules/.cache
            packages/*/dist
            packages/*/.vite
          key: ${{ runner.os }}-build-${{ matrix.app }}-${{ env.CACHE_VERSION }}-${{ hashFiles('apps/community/${{ matrix.app }}/src/**/*', 'apps/community/${{ matrix.app }}/package.json', 'packages/*/package.json') }}
          restore-keys: |
            ${{ runner.os }}-build-${{ matrix.app }}-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-build-${{ matrix.app }}-

      - name: å®‰è£…ä¾èµ–
        run: |
          echo "å®‰è£…workspaceä¾èµ–..."
          pnpm install --frozen-lockfile

      - name: æ„å»ºä¾èµ–åŒ…
        run: |
          echo "æ„å»ºshared packageså’Œä¾èµ–åŒ…..."

          # æ„å»ºshared packages
          pnpm --filter="@phoenixcoder/shared-*" run build || echo "æŸäº›shared packagesæ„å»ºå¤±è´¥"

          # æ„å»ºå½“å‰åº”ç”¨çš„ä¾èµ–åŒ…
          pnpm --filter="apps/community/${{ matrix.app }}^..." run build || echo "æŸäº›ä¾èµ–åŒ…æ„å»ºå¤±è´¥"

      - name: éªŒè¯åº”ç”¨é…ç½®
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "éªŒè¯ ${{ matrix.app }} åº”ç”¨é…ç½®..."

          # æ£€æŸ¥package.json
          if [ -f "package.json" ]; then
            echo "package.jsonå­˜åœ¨"
            cat package.json | jq '.name, .version, .scripts'
          fi

          # æ£€æŸ¥é…ç½®æ–‡ä»¶
          if [ -f "vite.config.ts" ]; then
            echo "vite.config.tså­˜åœ¨"
          fi

          # æ£€æŸ¥TypeScripté…ç½®
          if [ -f "tsconfig.json" ]; then
            echo "tsconfig.jsonå­˜åœ¨"
          fi

      - name: ç±»å‹æ£€æŸ¥
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡Œç±»å‹æ£€æŸ¥..."
          pnpm run type-check

      - name: ä»£ç æ£€æŸ¥
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡Œä»£ç æ£€æŸ¥..."
          pnpm run lint

      - name: å‰ç«¯ä¾èµ–å®‰å…¨æ‰«æ (npm audit)
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡Œå‰ç«¯ä¾èµ–å®‰å…¨æ‰«æ..."

          pnpm audit --audit-level=moderate --json > npm-audit-report.json || true
          pnpm audit --audit-level=moderate || true

          # æ£€æŸ¥é«˜å±æ¼æ´
          if [ -f "npm-audit-report.json" ]; then
            echo "åˆ†æå®‰å…¨æ¼æ´..."
            node -e "
            const audit = require('./npm-audit-report.json');
            if (audit.metadata && audit.metadata.vulnerabilities) {
              const { high, critical } = audit.metadata.vulnerabilities;
              console.log('é«˜å±æ¼æ´:', high || 0);
              console.log('ä¸¥é‡æ¼æ´:', critical || 0);
              if ((high || 0) + (critical || 0) > 0) {
                console.log('âš ï¸ å‘ç°é«˜å±æˆ–ä¸¥é‡å®‰å…¨æ¼æ´ï¼Œè¯·åŠæ—¶ä¿®å¤');
              }
            }
            " || true
          fi

      - name: å‰ç«¯å®‰å…¨æ£€æŸ¥ (ESLint Security)
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡ŒESLintå®‰å…¨æ£€æŸ¥..."

          # å®‰è£…ESLintå®‰å…¨æ’ä»¶
          pnpm add -D eslint-plugin-security eslint-plugin-no-secrets || true

          # è¿è¡Œå®‰å…¨æ£€æŸ¥
          npx eslint src/ \
            --ext .js,.jsx,.ts,.tsx \
            --config .eslintrc.security.js \
            --format json \
            --output-file eslint-security-report.json || true

          npx eslint src/ \
            --ext .js,.jsx,.ts,.tsx \
            --config .eslintrc.security.js || true

      - name: æ£€æŸ¥æ•æ„Ÿä¿¡æ¯æ³„éœ²
        working-directory: apps/community/${{ matrix.app }}
        run: |
          # æ£€æŸ¥å¸¸è§çš„æ•æ„Ÿä¿¡æ¯æ¨¡å¼
          echo "æ£€æŸ¥æ•æ„Ÿä¿¡æ¯æ³„éœ²..."

          # æ£€æŸ¥APIå¯†é’¥æ¨¡å¼
          if grep -r "api[_-]key\|apikey\|secret[_-]key" src/ --include="*.js" --include="*.jsx" --include="*.ts" --include="*.tsx" --include="*.json" | grep -v "example\|test\|mock"; then
            echo "âŒ å‘ç°å¯èƒ½çš„APIå¯†é’¥æ³„éœ²"
            exit 1
          fi

          # æ£€æŸ¥ç¡¬ç¼–ç çš„URLå’Œå¯†ç 
          if grep -r "password\s*=\|token\s*=" src/ --include="*.js" --include="*.jsx" --include="*.ts" --include="*.tsx" | grep -v "example\|test\|mock\|placeholder"; then
            echo "âŒ å‘ç°å¯èƒ½çš„ç¡¬ç¼–ç å¯†ç æˆ–ä»¤ç‰Œ"
            exit 1
          fi

          echo "âœ… æœªå‘ç°æ•æ„Ÿä¿¡æ¯æ³„éœ²"

      - name: æ£€æŸ¥ç¬¬ä¸‰æ–¹ä¾èµ–å®‰å…¨æ€§
        working-directory: apps/community/${{ matrix.app }}
        run: |
          # ä½¿ç”¨ Snyk æ£€æŸ¥ä¾èµ–æ¼æ´ï¼ˆå¦‚æœæœ‰ tokenï¼‰
          if [ -n "${{ secrets.SNYK_TOKEN }}" ]; then
            npx snyk test --json > snyk-report.json || true
            npx snyk test || true
          else
            echo "Snyk token not available, skipping Snyk scan"
          fi

          # æ£€æŸ¥è¿‡æ—¶çš„ä¾èµ–
          pnpm outdated --format json > outdated-deps.json || true

          # åˆ†æä¾èµ–æ ‘ä¸­çš„å®‰å…¨é—®é¢˜
          node -e "
          const fs = require('fs');

          try {
            const auditData = JSON.parse(fs.readFileSync('npm-audit-report.json', 'utf8'));
            const vulnerabilities = auditData.vulnerabilities || {};

            const highSeverity = Object.values(vulnerabilities).filter(v =>
              v.severity === 'high' || v.severity === 'critical'
            );

            if (highSeverity.length > 0) {
              console.log('âŒ å‘ç°é«˜å±æ¼æ´:', highSeverity.length);
              highSeverity.forEach(v => {
                console.log('  -', v.name, ':', v.severity);
              });
              process.exit(1);
            } else {
              console.log('âœ… æœªå‘ç°é«˜å±æ¼æ´');
            }
          } catch (e) {
            console.log('æ— æ³•è§£æauditæŠ¥å‘Šï¼Œè·³è¿‡æ£€æŸ¥');
          }
          " || true

      - name: è¿è¡Œå•å…ƒæµ‹è¯•
        working-directory: apps/community/${{ matrix.app }}
        env:
          APP_NAME: ${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡Œå•å…ƒæµ‹è¯•..."

          pnpm run test:unit \
            --coverage \
            --coverage.all \
            --coverage.lines=80 \
            --coverage.functions=80 \
            --coverage.branches=70 \
            --coverage.statements=80 \
            --reporter=verbose \
            --reporter=junit \
            --outputFile=test-results.xml

      - name: æ£€æŸ¥å‰ç«¯è¦†ç›–ç‡é˜ˆå€¼
        working-directory: apps/community/${{ matrix.app }}
        run: |
          if [ -f "coverage/coverage-summary.json" ]; then
            node -e "
            const fs = require('fs');
            const coverage = JSON.parse(fs.readFileSync('coverage/coverage-summary.json', 'utf8'));
            const total = coverage.total;

            console.log('[${{ matrix.app }}] Coverage Summary:');
            console.log('Lines:', total.lines.pct + '%');
            console.log('Statements:', total.statements.pct + '%');
            console.log('Functions:', total.functions.pct + '%');
            console.log('Branches:', total.branches.pct + '%');

            const thresholds = { lines: 80, statements: 80, functions: 80, branches: 70 };
            let failed = false;

            Object.keys(thresholds).forEach(key => {
              if (total[key].pct < thresholds[key]) {
                console.error('âŒ [${{ matrix.app }}]', key, 'coverage', total[key].pct + '% is below threshold', thresholds[key] + '%');
                failed = true;
              }
            });

            if (failed) process.exit(1);
            console.log('âœ… [${{ matrix.app }}] All coverage thresholds met');
            "
          fi

      - name: è¿è¡Œç»„ä»¶æµ‹è¯•
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡Œç»„ä»¶æµ‹è¯•..."
          pnpm run test:component --coverage

      - name: è¿è¡Œæ€§èƒ½æµ‹è¯•
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡Œæ€§èƒ½æµ‹è¯•..."
          pnpm run test:performance

      - name: æ„å»ºæ£€æŸ¥
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡Œæ„å»ºæ£€æŸ¥..."
          pnpm run build

          # æ£€æŸ¥æ„å»ºäº§ç‰©å¤§å°
          echo "æ„å»ºäº§ç‰©å¤§å°åˆ†æ:"
          du -sh dist/
          find dist/ -name "*.js" -exec du -h {} \; | sort -hr | head -10

          # æ£€æŸ¥æ„å»ºäº§ç‰©ç»“æ„
          echo "æ„å»ºäº§ç‰©ç»“æ„:"
          tree dist/ -L 3 || ls -la dist/

      - name: Bundleåˆ†æ
        working-directory: apps/community/${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] è¿è¡ŒBundleåˆ†æ..."
          pnpm run build:analyze || echo "Bundle analyze not available"
          ls -la dist/ || echo "No dist directory found"

      - name: ç”ŸæˆBundleæŠ¥å‘Š
        working-directory: apps/community/${{ matrix.app }}
        run: |
          if [ -f "dist/stats.json" ]; then
            echo "Bundle size analysis:" > bundle-report.txt
            du -sh dist/* >> bundle-report.txt || true
          fi

      - name: ä¸Šä¼ è¦†ç›–ç‡æŠ¥å‘Š
        uses: codecov/codecov-action@v3
        with:
          file: apps/community/${{ matrix.app }}/coverage/lcov.info
          flags: frontend-${{ matrix.app }}
          name: frontend-${{ matrix.app }}-coverage
          fail_ci_if_error: false

      - name: ä¸Šä¼ æµ‹è¯•ç»“æœ
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: ${{ matrix.app }}-test-results
          path: |
            apps/community/${{ matrix.app }}/test-results.xml
            apps/community/${{ matrix.app }}/coverage/
            apps/community/${{ matrix.app }}/dist/
            apps/community/${{ matrix.app }}/npm-audit-report.json
            apps/community/${{ matrix.app }}/eslint-security-report.json
            apps/community/${{ matrix.app }}/snyk-report.json
            apps/community/${{ matrix.app }}/outdated-deps.json

  # ç«¯åˆ°ç«¯æµ‹è¯•
  e2e-tests:
    name: ç«¯åˆ°ç«¯æµ‹è¯• - ${{ matrix.app }}
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]

    strategy:
      matrix:
        app: [community, enterprise]
      fail-fast: false  # å…è®¸ä¸€ä¸ªåº”ç”¨å¤±è´¥æ—¶ç»§ç»­æµ‹è¯•å…¶ä»–åº”ç”¨

    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'apps/${{ matrix.app }}/server/requirements*.txt'

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
          cache-dependency-path: '**/pnpm-lock.yaml'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
          run_install: false

      - name: è·å–pnpm storeç›®å½•
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: ç¼“å­˜pnpm store
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ env.CACHE_VERSION }}-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pnpm-store-

      - name: ç¼“å­˜Playwrightæµè§ˆå™¨
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/ms-playwright
            ~/Library/Caches/ms-playwright
          key: ${{ runner.os }}-playwright-${{ env.CACHE_VERSION }}-${{ hashFiles('apps/${{ matrix.app }}/admin/package.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-playwright-

      - name: æ„å»ºshared packages
        run: |
          echo "æ„å»ºshared packages..."
          pnpm install --frozen-lockfile
          pnpm --filter="@phoenixcoder/shared-*" run build || echo "æŸäº›shared packagesæ„å»ºå¤±è´¥"

      - name: å®‰è£…åç«¯ä¾èµ–
        working-directory: apps/${{ matrix.app }}/server
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: éªŒè¯æœåŠ¡é…ç½®
        working-directory: apps/${{ matrix.app }}/server
        run: |
          echo "éªŒè¯ ${{ matrix.app }} æœåŠ¡é…ç½®..."

          # æ£€æŸ¥æ•°æ®åº“è¿æ¥
          python -c "import psycopg2; conn = psycopg2.connect('postgresql://postgres:postgres@localhost:5432/test_db'); print('æ•°æ®åº“è¿æ¥æˆåŠŸ'); conn.close()"

          # æ£€æŸ¥Redisè¿æ¥
          python -c "import redis; r = redis.Redis(host='localhost', port=6379, db=0); r.ping(); print('Redisè¿æ¥æˆåŠŸ')"

          # æ£€æŸ¥é…ç½®æ–‡ä»¶
          if [ -f "config.py" ]; then
            echo "é…ç½®æ–‡ä»¶å­˜åœ¨"
          fi

      - name: å¯åŠ¨åç«¯æœåŠ¡
        working-directory: apps/${{ matrix.app }}/server
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          TESTING: true
          SERVICE_NAME: ${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] å¯åŠ¨åç«¯æœåŠ¡..."

          # è¿è¡Œæ•°æ®åº“è¿ç§»
          python manage.py migrate || echo "æ•°æ®åº“è¿ç§»å¤±è´¥æˆ–æœªé…ç½®"

          # åˆ›å»ºæµ‹è¯•æ•°æ®
          python manage.py loaddata fixtures/test_data.json || echo "æµ‹è¯•æ•°æ®åŠ è½½å¤±è´¥æˆ–æœªé…ç½®"

          # å¯åŠ¨æœåŠ¡
          python main.py &

          # ç­‰å¾…æœåŠ¡å¯åŠ¨
          echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
          for i in {1..30}; do
            if curl -f http://localhost:8000/health/ 2>/dev/null; then
              echo "æœåŠ¡å¯åŠ¨æˆåŠŸ"
              break
            fi
            echo "ç­‰å¾…æœåŠ¡å¯åŠ¨... ($i/30)"
            sleep 2
          done

      - name: æ„å»ºå‰ç«¯åº”ç”¨
        working-directory: apps/${{ matrix.app }}/admin
        env:
          APP_NAME: ${{ matrix.app }}
        run: |
          echo "[${{ matrix.app }}] æ„å»ºå‰ç«¯åº”ç”¨..."

          # æ„å»ºä¾èµ–åŒ…
          pnpm --filter="apps/${{ matrix.app }}/admin^..." run build || echo "æŸäº›ä¾èµ–åŒ…æ„å»ºå¤±è´¥"

          # æ„å»ºå½“å‰åº”ç”¨
          pnpm run build

          # éªŒè¯æ„å»ºäº§ç‰©
          if [ -d "dist" ]; then
            echo "æ„å»ºæˆåŠŸï¼Œäº§ç‰©å¤§å°:"
            du -sh dist/
          else
            echo "æ„å»ºå¤±è´¥ï¼Œæœªæ‰¾åˆ°distç›®å½•"
            exit 1
          fi

      - name: æ„å»ºäº§ç‰©å®‰å…¨æ‰«æ
        working-directory: apps/${{ matrix.app }}/admin
        run: |
          echo "[${{ matrix.app }}] æ£€æŸ¥æ„å»ºäº§ç‰©å®‰å…¨æ€§..."

          # æ£€æŸ¥æ„å»ºäº§ç‰©ä¸­çš„æ•æ„Ÿä¿¡æ¯
          if find dist/ -name "*.js" -o -name "*.css" -o -name "*.html" | xargs grep -l "api[_-]key\|secret\|password\|token" | grep -v "example\|test\|mock"; then
            echo "âŒ æ„å»ºäº§ç‰©ä¸­å‘ç°å¯èƒ½çš„æ•æ„Ÿä¿¡æ¯"
            find dist/ -name "*.js" -o -name "*.css" -o -name "*.html" | xargs grep -n "api[_-]key\|secret\|password\|token" | grep -v "example\|test\|mock" || true
            exit 1
          fi

          # æ£€æŸ¥æ„å»ºäº§ç‰©å¤§å°ï¼ˆé˜²æ­¢æ„å¤–åŒ…å«å¤§æ–‡ä»¶ï¼‰
          echo "æ£€æŸ¥æ„å»ºäº§ç‰©å¤§å°..."
          find dist/ -type f -size +5M -exec ls -lh {} \; | while read line; do
            echo "âš ï¸  å‘ç°å¤§æ–‡ä»¶: $line"
          done

          # æ£€æŸ¥æ˜¯å¦åŒ…å«æºç æ˜ å°„æ–‡ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒä¸åº”åŒ…å«ï¼‰
          if find dist/ -name "*.map" | head -1 | grep -q .; then
            echo "âš ï¸  æ„å»ºäº§ç‰©åŒ…å«æºç æ˜ å°„æ–‡ä»¶ï¼Œå¯èƒ½æ³„éœ²æºç ä¿¡æ¯"
            find dist/ -name "*.map" | head -5
          fi

          # æ£€æŸ¥CSPå’Œå®‰å…¨å¤´é…ç½®
          if [ -f "dist/index.html" ]; then
            if ! grep -q "Content-Security-Policy" dist/index.html; then
              echo "âš ï¸  æœªå‘ç°CSPé…ç½®ï¼Œå»ºè®®æ·»åŠ å†…å®¹å®‰å…¨ç­–ç•¥"
            fi
          fi

          # æ£€æŸ¥ç¯å¢ƒå˜é‡æ³„éœ²
          echo "æ£€æŸ¥ç¯å¢ƒå˜é‡æ³„éœ²..."
          grep -r "process\.env" dist/ || echo "æœªå‘ç°ç¯å¢ƒå˜é‡æ³„éœ²"

          echo "âœ… æ„å»ºäº§ç‰©å®‰å…¨æ£€æŸ¥å®Œæˆ"

      - name: è¿è¡Œæ—¶å®‰å…¨æ£€æŸ¥
        working-directory: apps/${{ matrix.app }}/admin
        run: |
          echo "[${{ matrix.app }}] æ£€æŸ¥è¿è¡Œæ—¶å®‰å…¨é…ç½®..."

          # æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
          if [ -f ".env.example" ]; then
            echo "æ£€æŸ¥ç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶..."
            if grep -q "password\|secret\|key" .env.example; then
              echo "âš ï¸  .env.example æ–‡ä»¶åŒ…å«æ•æ„Ÿå­—æ®µï¼Œè¯·ç¡®ä¿ä½¿ç”¨å ä½ç¬¦"
              grep "password\|secret\|key" .env.example || true
            fi
          fi

          # æ£€æŸ¥ä¾èµ–çš„è¿è¡Œæ—¶å®‰å…¨æ€§
          echo "æ£€æŸ¥è¿è¡Œæ—¶ä¾èµ–å®‰å…¨æ€§..."
          pnpm audit --audit-level=high --json > e2e-audit-report-${{ matrix.app }}.json || true

          # åˆ†æé«˜å±æ¼æ´
          node -e "
          const fs = require('fs');
          try {
            const auditData = JSON.parse(fs.readFileSync('e2e-audit-report-${{ matrix.app }}.json', 'utf8'));
            const vulnerabilities = auditData.vulnerabilities || {};

            const criticalVulns = Object.values(vulnerabilities).filter(v =>
              v.severity === 'critical'
            );

            if (criticalVulns.length > 0) {
              console.log('âŒ [${{ matrix.app }}] E2Eç¯å¢ƒå‘ç°ä¸¥é‡æ¼æ´:', criticalVulns.length);
              criticalVulns.forEach(v => {
                console.log('  -', v.name, ':', v.severity);
              });
              process.exit(1);
            } else {
              console.log('âœ… [${{ matrix.app }}] E2Eç¯å¢ƒæœªå‘ç°ä¸¥é‡æ¼æ´');
            }
          } catch (e) {
            console.log('æ— æ³•è§£æE2E auditæŠ¥å‘Šï¼Œè·³è¿‡æ£€æŸ¥');
          }
          " || true

          echo "âœ… è¿è¡Œæ—¶å®‰å…¨æ£€æŸ¥å®Œæˆ"

      - name: å®‰è£…Playwright
        working-directory: apps/${{ matrix.app }}/admin
        run: |
          echo "å®‰è£…Playwrightæµè§ˆå™¨..."
          pnpm exec playwright install --with-deps
          pnpm exec playwright install-deps

      - name: è¿è¡ŒE2Eæµ‹è¯•
        env:
          APP_NAME: ${{ matrix.app }}
          BASE_URL: http://localhost:8000
          FRONTEND_URL: http://localhost:3000
        run: |
          echo "[${{ matrix.app }}] è¿è¡ŒE2Eæµ‹è¯•..."

          # å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
          cd apps/${{ matrix.app }}/admin
          pnpm run preview --port 3000 &

          # ç­‰å¾…å‰ç«¯æœåŠ¡å¯åŠ¨
          echo "ç­‰å¾…å‰ç«¯æœåŠ¡å¯åŠ¨..."
          for i in {1..15}; do
            if curl -f http://localhost:3000 2>/dev/null; then
              echo "å‰ç«¯æœåŠ¡å¯åŠ¨æˆåŠŸ"
              break
            fi
            echo "ç­‰å¾…å‰ç«¯æœåŠ¡å¯åŠ¨... ($i/15)"
            sleep 2
          done

          # è¿è¡ŒE2Eæµ‹è¯•
          cd ../../../
          pnpm exec playwright test --config=apps/${{ matrix.app }}/admin/playwright.config.ts --reporter=html,json || echo "E2Eæµ‹è¯•å¤±è´¥æˆ–æœªé…ç½®"

      - name: ä¸Šä¼ E2Eæµ‹è¯•ç»“æœ
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results-${{ matrix.app }}
          path: |
            playwright-report/
            test-results/
            apps/${{ matrix.app }}/admin/e2e-audit-report-${{ matrix.app }}.json
            apps/${{ matrix.app }}/admin/playwright-report/
            apps/${{ matrix.app }}/admin/test-results/

  # é›†æˆæµ‹è¯•
  integration-tests:
    name: é›†æˆæµ‹è¯• - ${{ matrix.test-type }}
    runs-on: ubuntu-latest
    needs: [monorepo-deps, backend-tests, frontend-tests]

    strategy:
      matrix:
        test-type: [cross-service, api-integration, data-consistency]
      fail-fast: false  # å…è®¸ä¸€ç§æµ‹è¯•å¤±è´¥æ—¶ç»§ç»­å…¶ä»–æµ‹è¯•

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

      elasticsearch:
        image: elasticsearch:8.11.0
        env:
          discovery.type: single-node
          xpack.security.enabled: false
          ES_JAVA_OPTS: "-Xms512m -Xmx512m"
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health || exit 1"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5
        ports:
          - 9200:9200

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'tests/requirements*.txt'

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
          cache-dependency-path: '**/pnpm-lock.yaml'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}
          run_install: false

      - name: æ„å»ºshared packages
        run: |
          echo "æ„å»ºshared packages..."
          pnpm install --frozen-lockfile
          pnpm --filter="@phoenixcoder/shared-*" run build || echo "æŸäº›shared packagesæ„å»ºå¤±è´¥"

      - name: å®‰è£…Pythonä¾èµ–
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

          # å®‰è£…å„ä¸ªæœåŠ¡çš„ä¾èµ–
          for service in community enterprise; do
            if [ -f "apps/$service/server/requirements.txt" ]; then
              echo "å®‰è£… $service æœåŠ¡ä¾èµ–..."
              pip install -r "apps/$service/server/requirements.txt"
            fi
          done

      - name: å¯åŠ¨æ‰€æœ‰åç«¯æœåŠ¡
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          ELASTICSEARCH_URL: http://localhost:9200
          TESTING: true
        run: |
          echo "å¯åŠ¨æ‰€æœ‰åç«¯æœåŠ¡è¿›è¡Œé›†æˆæµ‹è¯•..."

          # è¿è¡Œæ•°æ®åº“è¿ç§»
          for service in community enterprise; do
            if [ -d "apps/$service/server" ]; then
              echo "[$service] è¿è¡Œæ•°æ®åº“è¿ç§»..."
              cd "apps/$service/server"
              python manage.py migrate || echo "$service æ•°æ®åº“è¿ç§»å¤±è´¥"
              cd ../../../
            fi
          done

          # å¯åŠ¨ç¤¾åŒºç‰ˆæœåŠ¡
          if [ -d "apps/community/server" ]; then
            echo "å¯åŠ¨ç¤¾åŒºç‰ˆæœåŠ¡..."
            cd apps/community/server
            python manage.py runserver 8001 &
            COMMUNITY_PID=$!
            cd ../../../
            echo "ç¤¾åŒºç‰ˆæœåŠ¡PID: $COMMUNITY_PID"
          fi

          # å¯åŠ¨ä¼ä¸šç‰ˆæœåŠ¡
          if [ -d "apps/enterprise/server" ]; then
            echo "å¯åŠ¨ä¼ä¸šç‰ˆæœåŠ¡..."
            cd apps/enterprise/server
            python manage.py runserver 8002 &
            ENTERPRISE_PID=$!
            cd ../../../
            echo "ä¼ä¸šç‰ˆæœåŠ¡PID: $ENTERPRISE_PID"
          fi

          # ç­‰å¾…æœåŠ¡å¯åŠ¨
          echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
          for port in 8001 8002; do
            for i in {1..30}; do
              if curl -f http://localhost:$port/health/ 2>/dev/null; then
                echo "ç«¯å£ $port æœåŠ¡å¯åŠ¨æˆåŠŸ"
                break
              fi
              echo "ç­‰å¾…ç«¯å£ $port æœåŠ¡å¯åŠ¨... ($i/30)"
              sleep 2
            done
          done

      - name: è¿è¡Œé›†æˆæµ‹è¯•
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          ELASTICSEARCH_URL: http://localhost:9200
          TESTING: true
          TEST_TYPE: ${{ matrix.test-type }}
          COMMUNITY_SERVICE_URL: http://localhost:8001
          ENTERPRISE_SERVICE_URL: http://localhost:8002
        run: |
          echo "[${{ matrix.test-type }}] è¿è¡Œé›†æˆæµ‹è¯•..."

          case "${{ matrix.test-type }}" in
            "cross-service")
              echo "è¿è¡Œè·¨æœåŠ¡é›†æˆæµ‹è¯•..."
              python -m pytest tests/integration/cross_service/ \
                --cov=apps \
                --cov-report=xml:coverage-cross-service.xml \
                --cov-report=html:htmlcov-cross-service \
                --cov-report=json:coverage-cross-service.json \
                --cov-fail-under=70 \
                --cov-branch \
                --junitxml=integration-cross-service-results.xml \
                --tb=short \
                --strict-markers \
                --strict-config \
                --maxfail=3 \
                --durations=10 \
                -v
              ;;
            "api-integration")
              echo "è¿è¡ŒAPIé›†æˆæµ‹è¯•..."
              python -m pytest tests/integration/api/ \
                --cov=apps \
                --cov-report=xml:coverage-api-integration.xml \
                --cov-report=html:htmlcov-api-integration \
                --cov-report=json:coverage-api-integration.json \
                --cov-fail-under=75 \
                --cov-branch \
                --junitxml=integration-api-results.xml \
                --tb=short \
                --strict-markers \
                --strict-config \
                --maxfail=5 \
                --durations=10 \
                -v
              ;;
            "data-consistency")
              echo "è¿è¡Œæ•°æ®ä¸€è‡´æ€§æµ‹è¯•..."
              python -m pytest tests/integration/data_consistency/ \
                --cov=apps \
                --cov-report=xml:coverage-data-consistency.xml \
                --cov-report=html:htmlcov-data-consistency \
                --cov-report=json:coverage-data-consistency.json \
                --cov-fail-under=80 \
                --cov-branch \
                --junitxml=integration-data-consistency-results.xml \
                --tb=short \
                --strict-markers \
                --strict-config \
                --maxfail=2 \
                --durations=10 \
                -v
              ;;
          esac

      - name: æ£€æŸ¥é›†æˆæµ‹è¯•è¦†ç›–ç‡
        run: |
          coverage_file="coverage-${{ matrix.test-type }}.json"
          if [ -f "$coverage_file" ]; then
            python -c "
            import json
            import sys

            test_type = '${{ matrix.test-type }}'

            with open('$coverage_file') as f:
                data = json.load(f)
            total = data['totals']
            lines_pct = total['percent_covered']
            branches_pct = total.get('percent_covered_display', 0)

            print(f'[$test_type] Integration Test Coverage Summary:')
            print(f'Lines coverage: {lines_pct}%')
            print(f'Branches coverage: {branches_pct}%')

            # ä¸åŒç±»å‹çš„é›†æˆæµ‹è¯•æœ‰ä¸åŒçš„è¦†ç›–ç‡é˜ˆå€¼
            thresholds = {
                'cross-service': {'lines': 70, 'branches': 60},
                'api-integration': {'lines': 75, 'branches': 65},
                'data-consistency': {'lines': 80, 'branches': 70}
            }

            threshold = thresholds.get(test_type, {'lines': 75, 'branches': 65})

            if lines_pct < threshold['lines']:
                print(f'âŒ [$test_type] Lines coverage {lines_pct}% is below threshold {threshold[\"lines\"]}%')
                sys.exit(1)
            if branches_pct < threshold['branches']:
                print(f'âŒ [$test_type] Branches coverage {branches_pct}% is below threshold {threshold[\"branches\"]}%')
                sys.exit(1)
            print(f'âœ… [$test_type] Integration test coverage thresholds met')
            "
          fi

      - name: ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        if: always()
        run: |
          echo "[${{ matrix.test-type }}] ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š..."

          # ç”Ÿæˆæµ‹è¯•æ‘˜è¦
          python -c "
          import json
          import xml.etree.ElementTree as ET
          from pathlib import Path

          test_type = '${{ matrix.test-type }}'

          # è§£æJUnit XMLç»“æœ
          xml_file = f'integration-{test_type.replace(\"-\", \"-\")}-results.xml'
          if Path(xml_file).exists():
              tree = ET.parse(xml_file)
              root = tree.getroot()

              total_tests = int(root.get('tests', 0))
              failures = int(root.get('failures', 0))
              errors = int(root.get('errors', 0))
              skipped = int(root.get('skipped', 0))
              time = float(root.get('time', 0))

              success_rate = ((total_tests - failures - errors) / total_tests * 100) if total_tests > 0 else 0

              summary = {
                  'test_type': test_type,
                  'total_tests': total_tests,
                  'passed': total_tests - failures - errors - skipped,
                  'failed': failures,
                  'errors': errors,
                  'skipped': skipped,
                  'success_rate': round(success_rate, 2),
                  'duration': round(time, 2)
              }

              with open(f'integration-{test_type}-summary.json', 'w') as f:
                  json.dump(summary, f, indent=2)

              print(f'[$test_type] æµ‹è¯•æ‘˜è¦:')
              print(f'  æ€»æµ‹è¯•æ•°: {total_tests}')
              print(f'  é€šè¿‡: {summary[\"passed\"]}')
              print(f'  å¤±è´¥: {failures}')
              print(f'  é”™è¯¯: {errors}')
              print(f'  è·³è¿‡: {skipped}')
              print(f'  æˆåŠŸç‡: {success_rate:.2f}%')
              print(f'  è€—æ—¶: {time:.2f}s')
          "

      - name: ä¸Šä¼ é›†æˆæµ‹è¯•ç»“æœ
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results-${{ matrix.test-type }}
          path: |
            integration-*-results.xml
            htmlcov-*/
            coverage-*.xml
            coverage-*.json
            integration-*-summary.json

  # è¦†ç›–ç‡æ±‡æ€»
  coverage-report:
    name: è¦†ç›–ç‡æ±‡æ€»
    runs-on: ubuntu-latest
    needs: [monorepo-deps, backend-tests, frontend-tests, integration-tests]
    if: always()

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: å®‰è£…è¦†ç›–ç‡å·¥å…·
        run: |
          # å®‰è£…Node.jsè¦†ç›–ç‡å·¥å…·
          pnpm add -g nyc c8 @istanbuljs/nyc-config-typescript

          # å®‰è£…Pythonè¦†ç›–ç‡å·¥å…·
          pip install coverage[toml] coverage-badge pytest-cov

      - name: ä¸‹è½½æ‰€æœ‰æµ‹è¯•ç»“æœ
        uses: actions/download-artifact@v3

      - name: ç»„ç»‡è¦†ç›–ç‡æ–‡ä»¶
        run: |
          mkdir -p coverage-reports/{backend,frontend,integration,summary}

          echo "ğŸ“ ç»„ç»‡è¦†ç›–ç‡æ–‡ä»¶..."

          # å¤åˆ¶åç«¯è¦†ç›–ç‡æ–‡ä»¶
          find . -name "*backend*coverage*.xml" -o -name "*backend*coverage*.json" | while read file; do
            if [[ "$file" == *"community"* ]]; then
              cp "$file" "coverage-reports/backend/community-$(basename "$file")"
            elif [[ "$file" == *"enterprise"* ]]; then
              cp "$file" "coverage-reports/backend/enterprise-$(basename "$file")"
            else
              cp "$file" "coverage-reports/backend/$(basename "$file")"
            fi
          done

          # å¤åˆ¶å‰ç«¯è¦†ç›–ç‡æ–‡ä»¶
          find . -name "*frontend*coverage*.xml" -o -name "*frontend*coverage*.json" | while read file; do
            if [[ "$file" == *"community"* ]]; then
              cp "$file" "coverage-reports/frontend/community-$(basename "$file")"
            elif [[ "$file" == *"enterprise"* ]]; then
              cp "$file" "coverage-reports/frontend/enterprise-$(basename "$file")"
            else
              cp "$file" "coverage-reports/frontend/$(basename "$file")"
            fi
          done

          # å¤åˆ¶é›†æˆæµ‹è¯•è¦†ç›–ç‡æ–‡ä»¶
          find . -name "*integration*coverage*.xml" -o -name "*integration*coverage*.json" | while read file; do
            cp "$file" "coverage-reports/integration/$(basename "$file")"
          done

          echo "ğŸ“Š è¦†ç›–ç‡æ–‡ä»¶ç»„ç»‡å®Œæˆ"
          ls -la coverage-reports/*/

      - name: ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
        run: |
          echo "ğŸ“Š ç”Ÿæˆ monorepo è¦†ç›–ç‡æŠ¥å‘Š..."

          # ä½¿ç”¨Pythonè„šæœ¬åˆ†æå’Œæ±‡æ€»è¦†ç›–ç‡
          python -c "
          import json
          import os
          import xml.etree.ElementTree as ET
          from pathlib import Path
          from collections import defaultdict
          import re

          def parse_coverage_xml(file_path):
              '''è§£æXMLæ ¼å¼çš„è¦†ç›–ç‡æ–‡ä»¶'''
              try:
                  tree = ET.parse(file_path)
                  root = tree.getroot()

                  # å°è¯•ä¸åŒçš„XMLæ ¼å¼
                  if root.tag == 'coverage':
                      # Coberturaæ ¼å¼
                      lines_valid = int(root.get('lines-valid', 0))
                      lines_covered = int(root.get('lines-covered', 0))
                      branches_valid = int(root.get('branches-valid', 0))
                      branches_covered = int(root.get('branches-covered', 0))

                      return {
                          'lines_pct': (lines_covered / lines_valid * 100) if lines_valid > 0 else 0,
                          'branches_pct': (branches_covered / branches_valid * 100) if branches_valid > 0 else 0,
                          'lines_total': lines_valid,
                          'lines_covered': lines_covered,
                          'branches_total': branches_valid,
                          'branches_covered': branches_covered
                      }
                  return None
              except Exception as e:
                  print(f'Error parsing XML {file_path}: {e}')
                  return None

          def parse_coverage_json(file_path):
              '''è§£æJSONæ ¼å¼çš„è¦†ç›–ç‡æ–‡ä»¶'''
              try:
                  with open(file_path) as f:
                      data = json.load(f)

                  totals = data.get('totals', {})
                  return {
                      'lines_pct': totals.get('percent_covered', 0),
                      'branches_pct': totals.get('percent_covered_display', 0),
                      'lines_total': totals.get('num_statements', 0),
                      'lines_covered': totals.get('covered_lines', 0),
                      'branches_total': totals.get('num_branches', 0),
                      'branches_covered': totals.get('covered_branches', 0)
                  }
              except Exception as e:
                  print(f'Error parsing JSON {file_path}: {e}')
                  return None

          # åˆ†æä¸åŒç±»å‹çš„è¦†ç›–ç‡
          coverage_data = {
              'services': defaultdict(dict),
              'apps': defaultdict(dict),
              'integration': defaultdict(dict),
              'summary': {}
          }

          # å¤„ç†åç«¯æœåŠ¡è¦†ç›–ç‡
          backend_dir = Path('coverage-reports/backend')
          if backend_dir.exists():
              for file in backend_dir.glob('*'):
                  service_name = 'community' if 'community' in file.name else 'enterprise' if 'enterprise' in file.name else 'shared'

                  if file.suffix == '.xml':
                      data = parse_coverage_xml(file)
                  elif file.suffix == '.json':
                      data = parse_coverage_json(file)
                  else:
                      continue

                  if data:
                      coverage_data['services'][service_name] = data

          # å¤„ç†å‰ç«¯åº”ç”¨è¦†ç›–ç‡
          frontend_dir = Path('coverage-reports/frontend')
          if frontend_dir.exists():
              for file in frontend_dir.glob('*'):
                  app_name = 'community' if 'community' in file.name else 'enterprise' if 'enterprise' in file.name else 'shared'

                  if file.suffix == '.xml':
                      data = parse_coverage_xml(file)
                  elif file.suffix == '.json':
                      data = parse_coverage_json(file)
                  else:
                      continue

                  if data:
                      coverage_data['apps'][app_name] = data

          # å¤„ç†é›†æˆæµ‹è¯•è¦†ç›–ç‡
          integration_dir = Path('coverage-reports/integration')
          if integration_dir.exists():
              for file in integration_dir.glob('*'):
                  test_type = 'cross-service' if 'cross-service' in file.name else 'api-integration' if 'api-integration' in file.name else 'data-consistency' if 'data-consistency' in file.name else 'general'

                  if file.suffix == '.xml':
                      data = parse_coverage_xml(file)
                  elif file.suffix == '.json':
                      data = parse_coverage_json(file)
                  else:
                      continue

                  if data:
                      coverage_data['integration'][test_type] = data

          # è®¡ç®—æ€»ä½“è¦†ç›–ç‡
          all_lines_total = 0
          all_lines_covered = 0
          all_branches_total = 0
          all_branches_covered = 0

          for category in ['services', 'apps']:
              for name, data in coverage_data[category].items():
                  all_lines_total += data.get('lines_total', 0)
                  all_lines_covered += data.get('lines_covered', 0)
                  all_branches_total += data.get('branches_total', 0)
                  all_branches_covered += data.get('branches_covered', 0)

          overall_lines_pct = (all_lines_covered / all_lines_total * 100) if all_lines_total > 0 else 0
          overall_branches_pct = (all_branches_covered / all_branches_total * 100) if all_branches_total > 0 else 0

          coverage_data['summary'] = {
              'overall_lines_pct': round(overall_lines_pct, 2),
              'overall_branches_pct': round(overall_branches_pct, 2),
              'total_lines': all_lines_total,
              'covered_lines': all_lines_covered,
              'total_branches': all_branches_total,
              'covered_branches': all_branches_covered
          }

          # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
          with open('coverage-reports/summary/detailed-report.json', 'w') as f:
              json.dump(coverage_data, f, indent=2)

          # ç”ŸæˆMarkdownæŠ¥å‘Š
          with open('coverage-reports/summary/coverage-report.md', 'w') as f:
              f.write('# ğŸ“Š Monorepo è¦†ç›–ç‡æŠ¥å‘Š\n\n')

              # æ€»ä½“è¦†ç›–ç‡
              f.write('## ğŸ¯ æ€»ä½“è¦†ç›–ç‡\n\n')
              f.write(f'- **è¡Œè¦†ç›–ç‡**: {overall_lines_pct:.2f}% ({all_lines_covered:,}/{all_lines_total:,})\n')
              f.write(f'- **åˆ†æ”¯è¦†ç›–ç‡**: {overall_branches_pct:.2f}% ({all_branches_covered:,}/{all_branches_total:,})\n\n')

              # åç«¯æœåŠ¡è¦†ç›–ç‡
              if coverage_data['services']:
                  f.write('## ğŸ”§ åç«¯æœåŠ¡è¦†ç›–ç‡\n\n')
                  f.write('| æœåŠ¡ | è¡Œè¦†ç›–ç‡ | åˆ†æ”¯è¦†ç›–ç‡ | æ€»è¡Œæ•° | å·²è¦†ç›–è¡Œæ•° |\n')
                  f.write('|------|----------|------------|--------|------------|\n')
                  for service, data in coverage_data['services'].items():
                      f.write(f'| {service} | {data.get("lines_pct", 0):.1f}% | {data.get("branches_pct", 0):.1f}% | {data.get("lines_total", 0):,} | {data.get("lines_covered", 0):,} |\n')
                  f.write('\n')

              # å‰ç«¯åº”ç”¨è¦†ç›–ç‡
              if coverage_data['apps']:
                  f.write('## ğŸ¨ å‰ç«¯åº”ç”¨è¦†ç›–ç‡\n\n')
                  f.write('| åº”ç”¨ | è¡Œè¦†ç›–ç‡ | åˆ†æ”¯è¦†ç›–ç‡ | æ€»è¡Œæ•° | å·²è¦†ç›–è¡Œæ•° |\n')
                  f.write('|------|----------|------------|--------|------------|\n')
                  for app, data in coverage_data['apps'].items():
                      f.write(f'| {app} | {data.get("lines_pct", 0):.1f}% | {data.get("branches_pct", 0):.1f}% | {data.get("lines_total", 0):,} | {data.get("lines_covered", 0):,} |\n')
                  f.write('\n')

              # é›†æˆæµ‹è¯•è¦†ç›–ç‡
              if coverage_data['integration']:
                  f.write('## ğŸ”— é›†æˆæµ‹è¯•è¦†ç›–ç‡\n\n')
                  f.write('| æµ‹è¯•ç±»å‹ | è¡Œè¦†ç›–ç‡ | åˆ†æ”¯è¦†ç›–ç‡ | æ€»è¡Œæ•° | å·²è¦†ç›–è¡Œæ•° |\n')
                  f.write('|----------|----------|------------|--------|------------|\n')
                  for test_type, data in coverage_data['integration'].items():
                      f.write(f'| {test_type} | {data.get("lines_pct", 0):.1f}% | {data.get("branches_pct", 0):.1f}% | {data.get("lines_total", 0):,} | {data.get("lines_covered", 0):,} |\n')
                  f.write('\n')

          # ç”Ÿæˆä¸åŒç»´åº¦çš„è¦†ç›–ç‡å¾½ç« 
          def generate_badge(label, value, threshold_good=85, threshold_ok=70):
              if value >= threshold_good:
                  color = 'brightgreen'
              elif value >= threshold_ok:
                  color = 'yellow'
              else:
                  color = 'red'
              return f'https://img.shields.io/badge/{label}-{value:.1f}%25-{color}'

          badges = {
              'overall': generate_badge('coverage', overall_lines_pct),
              'lines': generate_badge('lines', overall_lines_pct),
              'branches': generate_badge('branches', overall_branches_pct)
          }

          # ä¸ºæ¯ä¸ªæœåŠ¡å’Œåº”ç”¨ç”Ÿæˆå¾½ç« 
          for service, data in coverage_data['services'].items():
              badges[f'service-{service}'] = generate_badge(f'{service}-service', data.get('lines_pct', 0))

          for app, data in coverage_data['apps'].items():
              badges[f'app-{app}'] = generate_badge(f'{app}-app', data.get('lines_pct', 0))

          with open('coverage-reports/summary/badges.json', 'w') as f:
              json.dump(badges, f, indent=2)

          # ç”Ÿæˆå¾½ç« Markdown
          with open('coverage-reports/summary/badges.md', 'w') as f:
              f.write('# ğŸ“Š è¦†ç›–ç‡å¾½ç« \n\n')
              f.write('## æ€»ä½“è¦†ç›–ç‡\n\n')
              f.write(f'![Overall Coverage]({badges["overall"]})\n')
              f.write(f'![Lines Coverage]({badges["lines"]})\n')
              f.write(f'![Branches Coverage]({badges["branches"]})\n\n')

              if coverage_data['services']:
                  f.write('## åç«¯æœåŠ¡è¦†ç›–ç‡\n\n')
                  for service in coverage_data['services']:
                      f.write(f'![{service} Service]({badges[f"service-{service}"]})\n')
                  f.write('\n')

              if coverage_data['apps']:
                  f.write('## å‰ç«¯åº”ç”¨è¦†ç›–ç‡\n\n')
                  for app in coverage_data['apps']:
                      f.write(f'![{app} App]({badges[f"app-{app}"]})\n')
                  f.write('\n')

          print('âœ… Monorepo è¦†ç›–ç‡æŠ¥å‘Šç”Ÿæˆå®Œæˆ')
          print(f'ğŸ“Š æ€»ä½“è¡Œè¦†ç›–ç‡: {overall_lines_pct:.2f}%')
          print(f'ğŸŒ¿ æ€»ä½“åˆ†æ”¯è¦†ç›–ç‡: {overall_branches_pct:.2f}%')
          "

      - name: æ£€æŸ¥è¦†ç›–ç‡è¶‹åŠ¿
        run: |
          echo "ğŸ“ˆ æ£€æŸ¥è¦†ç›–ç‡è¶‹åŠ¿..."

          if [ -f "coverage-reports/summary/detailed-report.json" ] && [ -f ".github/coverage-baseline.json" ]; then
            python -c "
            import json

            # è¯»å–å½“å‰è¦†ç›–ç‡æŠ¥å‘Š
            with open('coverage-reports/summary/detailed-report.json') as f:
                current = json.load(f)

            # è¯»å–åŸºçº¿è¦†ç›–ç‡
            with open('.github/coverage-baseline.json') as f:
                baseline = json.load(f)

            current_summary = current.get('summary', {})
            baseline_summary = baseline.get('summary', {})

            current_lines_pct = current_summary.get('overall_lines_pct', 0)
            baseline_lines_pct = baseline_summary.get('overall_lines_pct', 0)

            current_branches_pct = current_summary.get('overall_branches_pct', 0)
            baseline_branches_pct = baseline_summary.get('overall_branches_pct', 0)

            lines_diff = current_lines_pct - baseline_lines_pct
            branches_diff = current_branches_pct - baseline_branches_pct

            print('ğŸ“Š è¦†ç›–ç‡è¶‹åŠ¿åˆ†æ:')
            print(f'  è¡Œè¦†ç›–ç‡: {baseline_lines_pct:.2f}% â†’ {current_lines_pct:.2f}% ({lines_diff:+.2f}%)')
            print(f'  åˆ†æ”¯è¦†ç›–ç‡: {baseline_branches_pct:.2f}% â†’ {current_branches_pct:.2f}% ({branches_diff:+.2f}%)')

            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾è‘—ä¸‹é™
            significant_decline = False

            if lines_diff < -2:  # è¡Œè¦†ç›–ç‡ä¸‹é™è¶…è¿‡2%
                print(f'âŒ è¡Œè¦†ç›–ç‡ä¸‹é™ {abs(lines_diff):.2f}%ï¼Œè¶…è¿‡é˜ˆå€¼ 2%')
                significant_decline = True

            if branches_diff < -3:  # åˆ†æ”¯è¦†ç›–ç‡ä¸‹é™è¶…è¿‡3%
                print(f'âŒ åˆ†æ”¯è¦†ç›–ç‡ä¸‹é™ {abs(branches_diff):.2f}%ï¼Œè¶…è¿‡é˜ˆå€¼ 3%')
                significant_decline = True

            # æ£€æŸ¥å„ä¸ªæœåŠ¡å’Œåº”ç”¨çš„è¦†ç›–ç‡å˜åŒ–
            for category in ['services', 'apps']:
                current_items = current.get(category, {})
                baseline_items = baseline.get(category, {})

                for name, current_data in current_items.items():
                    if name in baseline_items:
                        baseline_data = baseline_items[name]

                        current_item_pct = current_data.get('lines_pct', 0)
                        baseline_item_pct = baseline_data.get('lines_pct', 0)
                        item_diff = current_item_pct - baseline_item_pct

                        if item_diff < -5:  # å•ä¸ªé¡¹ç›®è¦†ç›–ç‡ä¸‹é™è¶…è¿‡5%
                            print(f'âš ï¸ {category[:-1]} \"{name}\" è¦†ç›–ç‡ä¸‹é™ {abs(item_diff):.2f}%')
                            significant_decline = True
                        elif item_diff > 3:  # å•ä¸ªé¡¹ç›®è¦†ç›–ç‡æå‡è¶…è¿‡3%
                            print(f'ğŸ‰ {category[:-1]} \"{name}\" è¦†ç›–ç‡æå‡ {item_diff:.2f}%')

            if significant_decline:
                print('\nâŒ æ£€æµ‹åˆ°æ˜¾è‘—çš„è¦†ç›–ç‡ä¸‹é™ï¼Œè¯·æ£€æŸ¥ä»£ç å˜æ›´')
                exit(1)
            elif lines_diff > 1 or branches_diff > 1:
                print('\nğŸ‰ è¦†ç›–ç‡æœ‰æ‰€æå‡ï¼')
            else:
                print('\nâœ… è¦†ç›–ç‡ä¿æŒç¨³å®š')
            "
          else
            echo "âš ï¸ æœªæ‰¾åˆ°åŸºçº¿è¦†ç›–ç‡æ–‡ä»¶ï¼Œè·³è¿‡è¶‹åŠ¿æ£€æŸ¥"
          fi

      - name: æ›´æ–°è¦†ç›–ç‡åŸºçº¿
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          echo "ğŸ“ æ›´æ–°è¦†ç›–ç‡åŸºçº¿..."

          if [ -f "coverage-reports/summary/detailed-report.json" ]; then
            cp "coverage-reports/summary/detailed-report.json" ".github/coverage-baseline.json"
            echo "âœ… è¦†ç›–ç‡åŸºçº¿å·²æ›´æ–°"
          fi

      - name: ä¸Šä¼ è¦†ç›–ç‡æŠ¥å‘Š
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: coverage-report
          path: |
            coverage-reports/
            .github/coverage-baseline.json

      - name: è¯„è®ºPRè¦†ç›–ç‡
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const detailedReportPath = 'coverage-reports/summary/detailed-report.json';
            const badgesPath = 'coverage-reports/summary/badges.json';

            if (fs.existsSync(detailedReportPath)) {
              const coverage = JSON.parse(fs.readFileSync(detailedReportPath, 'utf8'));
              const badges = fs.existsSync(badgesPath) ? JSON.parse(fs.readFileSync(badgesPath, 'utf8')) : {};

              const summary = coverage.summary || {};
              const services = coverage.services || {};
              const apps = coverage.apps || {};
              const integration = coverage.integration || {};

              let comment = `## ğŸ“Š Monorepo æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š\n\n`;

              // æ€»ä½“è¦†ç›–ç‡å¾½ç« 
              if (badges.overall) {
                comment += `![Overall Coverage](${badges.overall}) `;
              }
              if (badges.lines) {
                comment += `![Lines](${badges.lines}) `;
              }
              if (badges.branches) {
                comment += `![Branches](${badges.branches})`;
              }
              comment += `\n\n`;

              // æ€»ä½“è¦†ç›–ç‡æ‘˜è¦
              comment += `### ğŸ¯ æ€»ä½“è¦†ç›–ç‡\n\n`;
              comment += `- **è¡Œè¦†ç›–ç‡**: ${summary.overall_lines_pct || 0}% (${(summary.covered_lines || 0).toLocaleString()}/${(summary.total_lines || 0).toLocaleString()})\n`;
              comment += `- **åˆ†æ”¯è¦†ç›–ç‡**: ${summary.overall_branches_pct || 0}% (${(summary.covered_branches || 0).toLocaleString()}/${(summary.total_branches || 0).toLocaleString()})\n\n`;

              // åç«¯æœåŠ¡è¦†ç›–ç‡
              if (Object.keys(services).length > 0) {
                comment += `### ğŸ”§ åç«¯æœåŠ¡è¦†ç›–ç‡\n\n`;
                comment += `| æœåŠ¡ | å¾½ç«  | è¡Œè¦†ç›–ç‡ | åˆ†æ”¯è¦†ç›–ç‡ | æ€»è¡Œæ•° |\n`;
                comment += `|------|------|----------|------------|--------|\n`;

                for (const [service, data] of Object.entries(services)) {
                  const badge = badges[\`service-\${service}\`] ? \`![\${service}](\${badges[\`service-\${service}\`]})\` : '-';
                  comment += \`| \${service} | \${badge} | \${(data.lines_pct || 0).toFixed(1)}% | \${(data.branches_pct || 0).toFixed(1)}% | \${(data.lines_total || 0).toLocaleString()} |\n\`;
                }
                comment += `\n`;
              }

              // å‰ç«¯åº”ç”¨è¦†ç›–ç‡
              if (Object.keys(apps).length > 0) {
                comment += `### ğŸ¨ å‰ç«¯åº”ç”¨è¦†ç›–ç‡\n\n`;
                comment += `| åº”ç”¨ | å¾½ç«  | è¡Œè¦†ç›–ç‡ | åˆ†æ”¯è¦†ç›–ç‡ | æ€»è¡Œæ•° |\n`;
                comment += `|------|------|----------|------------|--------|\n`;

                for (const [app, data] of Object.entries(apps)) {
                  const badge = badges[\`app-\${app}\`] ? \`![\${app}](\${badges[\`app-\${app}\`]})\` : '-';
                  comment += \`| \${app} | \${badge} | \${(data.lines_pct || 0).toFixed(1)}% | \${(data.branches_pct || 0).toFixed(1)}% | \${(data.lines_total || 0).toLocaleString()} |\n\`;
                }
                comment += `\n`;
              }

              // é›†æˆæµ‹è¯•è¦†ç›–ç‡
              if (Object.keys(integration).length > 0) {
                comment += `### ğŸ”— é›†æˆæµ‹è¯•è¦†ç›–ç‡\n\n`;
                comment += `| æµ‹è¯•ç±»å‹ | è¡Œè¦†ç›–ç‡ | åˆ†æ”¯è¦†ç›–ç‡ | æ€»è¡Œæ•° |\n`;
                comment += `|----------|----------|------------|--------|\n`;

                for (const [testType, data] of Object.entries(integration)) {
                  comment += \`| \${testType} | \${(data.lines_pct || 0).toFixed(1)}% | \${(data.branches_pct || 0).toFixed(1)}% | \${(data.lines_total || 0).toLocaleString()} |\n\`;
                }
                comment += `\n`;
              }

              comment += `\nğŸ“ˆ [æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š](\${process.env.GITHUB_SERVER_URL}/\${process.env.GITHUB_REPOSITORY}/actions/runs/\${process.env.GITHUB_RUN_ID})`;

              // æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç°æœ‰çš„è¦†ç›–ç‡è¯„è®º
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
              });

              const existingComment = comments.find(comment =>
                comment.user.type === 'Bot' && comment.body.includes('ğŸ“Š Monorepo æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š')
              );

              if (existingComment) {
                // æ›´æ–°ç°æœ‰è¯„è®º
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: existingComment.id,
                  body: comment
                });
              } else {
                // åˆ›å»ºæ–°è¯„è®º
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: comment
                });
              }
            } else {
              console.log('æœªæ‰¾åˆ°è¦†ç›–ç‡æŠ¥å‘Šæ–‡ä»¶ï¼Œè·³è¿‡PRè¯„è®º');
            }

  # æ€§èƒ½å›å½’æ£€æµ‹
  performance-regression:
    name: æ€§èƒ½å›å½’æ£€æµ‹ (${{ matrix.component }})
    runs-on: ubuntu-latest
    needs: [monorepo-deps, backend-tests, frontend-tests, e2e-tests]
    if: github.event_name == 'pull_request'

    strategy:
      matrix:
        component: [backend-services, frontend-apps, e2e-performance]
      fail-fast: false

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ä¸‹è½½æ€§èƒ½æµ‹è¯•ç»“æœ
        uses: actions/download-artifact@v3
        with:
          pattern: '*-test-results'
          merge-multiple: true

      - name: å®‰è£…æ€§èƒ½åˆ†æå·¥å…·
        run: |
          echo "ğŸ“Š å®‰è£…æ€§èƒ½åˆ†æå·¥å…·..."

          # å®‰è£…Node.jsæ€§èƒ½åˆ†æå·¥å…·
          pnpm add -g clinic autocannon lighthouse-ci

          # å®‰è£…Pythonæ€§èƒ½åˆ†æå·¥å…·
          pip install py-spy memory-profiler psutil

          # åˆ›å»ºæ€§èƒ½åˆ†æè„šæœ¬
          cat > performance-analyzer.py << 'EOF'
          import json
          import os
          import sys
          from pathlib import Path
          import statistics

          def analyze_backend_performance():
              """åˆ†æåç«¯æœåŠ¡æ€§èƒ½"""
              results = {}

              # æŸ¥æ‰¾åç«¯æ€§èƒ½æµ‹è¯•ç»“æœ
              for service_dir in Path('.').glob('*-backend-test-results'):
                  service_name = service_dir.name.replace('-backend-test-results', '')

                  perf_file = service_dir / 'performance.json'
                  if perf_file.exists():
                      with open(perf_file) as f:
                          perf_data = json.load(f)

                      results[service_name] = {
                          'response_time_p95': perf_data.get('response_time_p95', 0),
                          'throughput': perf_data.get('throughput', 0),
                          'memory_usage': perf_data.get('memory_usage', 0),
                          'cpu_usage': perf_data.get('cpu_usage', 0)
                      }

              return results

          def analyze_frontend_performance():
              """åˆ†æå‰ç«¯åº”ç”¨æ€§èƒ½"""
              results = {}

              # æŸ¥æ‰¾å‰ç«¯æ€§èƒ½æµ‹è¯•ç»“æœ
              for app_dir in Path('.').glob('*-frontend-test-results'):
                  app_name = app_dir.name.replace('-frontend-test-results', '')

                  lighthouse_file = app_dir / 'lighthouse-report.json'
                  if lighthouse_file.exists():
                      with open(lighthouse_file) as f:
                          lighthouse_data = json.load(f)

                      audits = lighthouse_data.get('audits', {})
                      results[app_name] = {
                          'performance_score': lighthouse_data.get('categories', {}).get('performance', {}).get('score', 0) * 100,
                          'first_contentful_paint': audits.get('first-contentful-paint', {}).get('numericValue', 0),
                          'largest_contentful_paint': audits.get('largest-contentful-paint', {}).get('numericValue', 0),
                          'cumulative_layout_shift': audits.get('cumulative-layout-shift', {}).get('numericValue', 0),
                          'total_blocking_time': audits.get('total-blocking-time', {}).get('numericValue', 0)
                      }

              return results

          def analyze_e2e_performance():
              """åˆ†æE2Eæµ‹è¯•æ€§èƒ½"""
              results = {}

              # æŸ¥æ‰¾E2Eæ€§èƒ½æµ‹è¯•ç»“æœ
              for app_dir in Path('.').glob('*-e2e-test-results'):
                  app_name = app_dir.name.replace('-e2e-test-results', '')

                  perf_file = app_dir / 'e2e-performance.json'
                  if perf_file.exists():
                      with open(perf_file) as f:
                          perf_data = json.load(f)

                      results[app_name] = {
                          'test_duration': perf_data.get('total_duration', 0),
                          'page_load_time': perf_data.get('avg_page_load_time', 0),
                          'interaction_time': perf_data.get('avg_interaction_time', 0),
                          'network_requests': perf_data.get('avg_network_requests', 0)
                      }

              return results

          def compare_with_baseline(current_data, baseline_file):
              """ä¸åŸºçº¿æ€§èƒ½æ•°æ®æ¯”è¾ƒ"""
              if not os.path.exists(baseline_file):
                  print(f"âš ï¸ æœªæ‰¾åˆ°åŸºçº¿æ–‡ä»¶ {baseline_file}ï¼Œè·³è¿‡æ¯”è¾ƒ")
                  return []

              with open(baseline_file) as f:
                  baseline_data = json.load(f)

              regressions = []
              improvements = []

              for component, metrics in current_data.items():
                  if component not in baseline_data:
                      continue

                  baseline_metrics = baseline_data[component]

                  for metric, current_value in metrics.items():
                      if metric not in baseline_metrics:
                          continue

                      baseline_value = baseline_metrics[metric]
                      if baseline_value == 0:
                          continue

                      change_pct = ((current_value - baseline_value) / baseline_value) * 100

                      # å®šä¹‰å›å½’é˜ˆå€¼ï¼ˆä¸åŒæŒ‡æ ‡æœ‰ä¸åŒçš„é˜ˆå€¼ï¼‰
                      thresholds = {
                          'response_time_p95': 15,  # å“åº”æ—¶é—´å¢åŠ 15%ä¸ºå›å½’
                          'throughput': -10,  # ååé‡ä¸‹é™10%ä¸ºå›å½’
                          'memory_usage': 20,  # å†…å­˜ä½¿ç”¨å¢åŠ 20%ä¸ºå›å½’
                          'cpu_usage': 25,  # CPUä½¿ç”¨å¢åŠ 25%ä¸ºå›å½’
                          'performance_score': -5,  # æ€§èƒ½åˆ†æ•°ä¸‹é™5%ä¸ºå›å½’
                          'first_contentful_paint': 20,  # FCPå¢åŠ 20%ä¸ºå›å½’
                          'largest_contentful_paint': 20,  # LCPå¢åŠ 20%ä¸ºå›å½’
                          'cumulative_layout_shift': 50,  # CLSå¢åŠ 50%ä¸ºå›å½’
                          'total_blocking_time': 30,  # TBTå¢åŠ 30%ä¸ºå›å½’
                          'test_duration': 25,  # æµ‹è¯•æ—¶é•¿å¢åŠ 25%ä¸ºå›å½’
                          'page_load_time': 20,  # é¡µé¢åŠ è½½æ—¶é—´å¢åŠ 20%ä¸ºå›å½’
                          'interaction_time': 30,  # äº¤äº’æ—¶é—´å¢åŠ 30%ä¸ºå›å½’
                      }

                      threshold = thresholds.get(metric, 15)  # é»˜è®¤15%é˜ˆå€¼

                      # å¯¹äº"è¶Šå°è¶Šå¥½"çš„æŒ‡æ ‡ï¼Œæ­£å˜åŒ–æ˜¯å›å½’
                      # å¯¹äº"è¶Šå¤§è¶Šå¥½"çš„æŒ‡æ ‡ï¼Œè´Ÿå˜åŒ–æ˜¯å›å½’
                      better_when_lower = metric in [
                          'response_time_p95', 'memory_usage', 'cpu_usage',
                          'first_contentful_paint', 'largest_contentful_paint',
                          'cumulative_layout_shift', 'total_blocking_time',
                          'test_duration', 'page_load_time', 'interaction_time'
                      ]

                      if better_when_lower:
                          if change_pct > threshold:
                              regressions.append({
                                  'component': component,
                                  'metric': metric,
                                  'baseline_value': baseline_value,
                                  'current_value': current_value,
                                  'change_pct': change_pct,
                                  'threshold': threshold
                              })
                          elif change_pct < -5:  # æ”¹å–„è¶…è¿‡5%
                              improvements.append({
                                  'component': component,
                                  'metric': metric,
                                  'baseline_value': baseline_value,
                                  'current_value': current_value,
                                  'change_pct': change_pct
                              })
                      else:
                          if change_pct < -abs(threshold):
                              regressions.append({
                                  'component': component,
                                  'metric': metric,
                                  'baseline_value': baseline_value,
                                  'current_value': current_value,
                                  'change_pct': change_pct,
                                  'threshold': threshold
                              })
                          elif change_pct > 5:  # æ”¹å–„è¶…è¿‡5%
                              improvements.append({
                                  'component': component,
                                  'metric': metric,
                                  'baseline_value': baseline_value,
                                  'current_value': current_value,
                                  'change_pct': change_pct
                              })

              return regressions, improvements

          def main():
              component = os.environ.get('MATRIX_COMPONENT', 'backend-services')

              print(f"ğŸ” åˆ†æ {component} æ€§èƒ½æ•°æ®...")

              if component == 'backend-services':
                  current_data = analyze_backend_performance()
                  baseline_file = '.github/performance-baseline-backend.json'
              elif component == 'frontend-apps':
                  current_data = analyze_frontend_performance()
                  baseline_file = '.github/performance-baseline-frontend.json'
              elif component == 'e2e-performance':
                  current_data = analyze_e2e_performance()
                  baseline_file = '.github/performance-baseline-e2e.json'
              else:
                  print(f"âŒ æœªçŸ¥çš„ç»„ä»¶ç±»å‹: {component}")
                  sys.exit(1)

              if not current_data:
                  print(f"âš ï¸ æœªæ‰¾åˆ° {component} çš„æ€§èƒ½æ•°æ®")
                  return

              print(f"ğŸ“Š æ‰¾åˆ° {len(current_data)} ä¸ªç»„ä»¶çš„æ€§èƒ½æ•°æ®")

              # ä¸åŸºçº¿æ¯”è¾ƒ
              regressions, improvements = compare_with_baseline(current_data, baseline_file)

              # ç”ŸæˆæŠ¥å‘Š
              report = {
                  'component_type': component,
                  'timestamp': os.environ.get('GITHUB_RUN_ID', ''),
                  'current_data': current_data,
                  'regressions': regressions,
                  'improvements': improvements,
                  'summary': {
                      'total_components': len(current_data),
                      'regressions_count': len(regressions),
                      'improvements_count': len(improvements)
                  }
              }

              # ä¿å­˜æŠ¥å‘Š
              os.makedirs('performance-reports', exist_ok=True)
              report_file = f'performance-reports/{component}-report.json'

              with open(report_file, 'w') as f:
                  json.dump(report, f, indent=2)

              print(f"ğŸ“ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")

              # è¾“å‡ºæ‘˜è¦
              if regressions:
                  print(f"âŒ å‘ç° {len(regressions)} ä¸ªæ€§èƒ½å›å½’")
                  for reg in regressions:
                      print(f"  - {reg['component']}.{reg['metric']}: {reg['change_pct']:+.1f}% (é˜ˆå€¼: {reg['threshold']}%)")

              if improvements:
                  print(f"ğŸ‰ å‘ç° {len(improvements)} ä¸ªæ€§èƒ½æ”¹å–„")
                  for imp in improvements:
                      print(f"  - {imp['component']}.{imp['metric']}: {imp['change_pct']:+.1f}%")

              if not regressions and not improvements:
                  print("âœ… æ€§èƒ½ä¿æŒç¨³å®š")

          if __name__ == '__main__':
              main()
          EOF

      - name: è¿è¡Œæ€§èƒ½å›å½’æ£€æµ‹
        env:
          MATRIX_COMPONENT: ${{ matrix.component }}
        run: |
          echo "ğŸ” è¿è¡Œ ${{ matrix.component }} æ€§èƒ½å›å½’æ£€æµ‹..."
          python performance-analyzer.py

      - name: ä¸Šä¼ æ€§èƒ½æŠ¥å‘Š
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-report-${{ matrix.component }}
          path: performance-reports/

      - name: è¯„è®ºPRæ€§èƒ½æŠ¥å‘Š
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const component = '${{ matrix.component }}';
            const reportPath = `performance-reports/${component}-report.json`;

            if (fs.existsSync(reportPath)) {
              const report = JSON.parse(fs.readFileSync(reportPath, 'utf8'));

              const componentNames = {
                'backend-services': 'ğŸ”§ åç«¯æœåŠ¡',
                'frontend-apps': 'ğŸ¨ å‰ç«¯åº”ç”¨',
                'e2e-performance': 'ğŸ”— E2Eæµ‹è¯•'
              };

              const componentName = componentNames[component] || component;

              let comment = `## ğŸ“Š ${componentName} æ€§èƒ½å›å½’æ£€æµ‹\n\n`;

              const summary = report.summary || {};
              comment += `**æ£€æµ‹æ‘˜è¦**: ${summary.total_components || 0} ä¸ªç»„ä»¶ï¼Œ${summary.regressions_count || 0} ä¸ªå›å½’ï¼Œ${summary.improvements_count || 0} ä¸ªæ”¹å–„\n\n`;

              // æ€§èƒ½å›å½’
              if (report.regressions && report.regressions.length > 0) {
                comment += `### âŒ æ€§èƒ½å›å½’ (${report.regressions.length})\n\n`;
                comment += `| ç»„ä»¶ | æŒ‡æ ‡ | åŸºçº¿å€¼ | å½“å‰å€¼ | å˜åŒ– | é˜ˆå€¼ |\n`;
                comment += `|------|------|--------|--------|------|------|\n`;

                for (const reg of report.regressions) {
                  const baselineStr = typeof reg.baseline_value === 'number' ? reg.baseline_value.toFixed(2) : reg.baseline_value;
                  const currentStr = typeof reg.current_value === 'number' ? reg.current_value.toFixed(2) : reg.current_value;
                  comment += `| ${reg.component} | ${reg.metric} | ${baselineStr} | ${currentStr} | ${reg.change_pct > 0 ? '+' : ''}${reg.change_pct.toFixed(1)}% | ${reg.threshold}% |\n`;
                }
                comment += `\n`;
              }

              // æ€§èƒ½æ”¹å–„
              if (report.improvements && report.improvements.length > 0) {
                comment += `### ğŸ‰ æ€§èƒ½æ”¹å–„ (${report.improvements.length})\n\n`;
                comment += `| ç»„ä»¶ | æŒ‡æ ‡ | åŸºçº¿å€¼ | å½“å‰å€¼ | å˜åŒ– |\n`;
                comment += `|------|------|--------|--------|------|\n`;

                for (const imp of report.improvements) {
                  const baselineStr = typeof imp.baseline_value === 'number' ? imp.baseline_value.toFixed(2) : imp.baseline_value;
                  const currentStr = typeof imp.current_value === 'number' ? imp.current_value.toFixed(2) : imp.current_value;
                  comment += `| ${imp.component} | ${imp.metric} | ${baselineStr} | ${currentStr} | ${imp.change_pct > 0 ? '+' : ''}${imp.change_pct.toFixed(1)}% |\n`;
                }
                comment += `\n`;
              }

              if (!report.regressions?.length && !report.improvements?.length) {
                comment += `âœ… æ€§èƒ½ä¿æŒç¨³å®šï¼Œæœªæ£€æµ‹åˆ°æ˜¾è‘—å˜åŒ–ã€‚\n\n`;
              }

              comment += `\nğŸ“ˆ [æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š](\${process.env.GITHUB_SERVER_URL}/\${process.env.GITHUB_REPOSITORY}/actions/runs/\${process.env.GITHUB_RUN_ID})`;

              // æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç°æœ‰çš„æ€§èƒ½è¯„è®º
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
              });

              const existingComment = comments.find(comment =>
                comment.user.type === 'Bot' && comment.body.includes(`ğŸ“Š ${componentName} æ€§èƒ½å›å½’æ£€æµ‹`)
              );

              if (existingComment) {
                // æ›´æ–°ç°æœ‰è¯„è®º
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: existingComment.id,
                  body: comment
                });
              } else {
                // åˆ›å»ºæ–°è¯„è®º
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: comment
                });
              }
            } else {
              console.log(`æœªæ‰¾åˆ° ${component} æ€§èƒ½æŠ¥å‘Šæ–‡ä»¶ï¼Œè·³è¿‡PRè¯„è®º`);
            }

  # éƒ¨ç½²æ£€æŸ¥
  deployment-check:
    name: éƒ¨ç½²æ£€æŸ¥ (${{ matrix.environment }})
    runs-on: ubuntu-latest
    needs: [monorepo-deps, code-quality, backend-tests, frontend-tests, e2e-tests, integration-tests, coverage-report]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'

    strategy:
      matrix:
        environment: [staging, production]
      fail-fast: false

    environment:
      name: ${{ matrix.environment }}
      url: ${{ steps.deploy-url.outputs.url }}

    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4

      - name: è®¾ç½®Node.jsç¯å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: å®‰è£…pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: å®‰è£…ä¾èµ–
        run: |
          echo "ğŸ“¦ å®‰è£…é¡¹ç›®ä¾èµ–..."
          pnpm install --frozen-lockfile

      - name: æ„å»ºå…±äº«åŒ…
        run: |
          echo "ğŸ”§ æ„å»ºå…±äº«åŒ…..."
          pnpm --filter "./packages/*" build

      - name: æ£€æŸ¥éƒ¨ç½²é…ç½®
        env:
          ENVIRONMENT: ${{ matrix.environment }}
        run: |
          echo "ğŸ” æ£€æŸ¥ $ENVIRONMENT ç¯å¢ƒéƒ¨ç½²é…ç½®..."

          # æ£€æŸ¥ç¯å¢ƒé…ç½®æ–‡ä»¶
          if [ ! -f "deploy/environments/$ENVIRONMENT.env" ]; then
            echo "âŒ æœªæ‰¾åˆ°ç¯å¢ƒé…ç½®æ–‡ä»¶: deploy/environments/$ENVIRONMENT.env"
            exit 1
          fi

          echo "âœ… ç¯å¢ƒé…ç½®æ–‡ä»¶å­˜åœ¨"

          # æ£€æŸ¥Dockeré…ç½®
          echo "ğŸ³ æ£€æŸ¥Dockeré…ç½®..."

          # æ£€æŸ¥å„ä¸ªæœåŠ¡çš„Dockerfile
          for service in community enterprise; do
            dockerfile="apps/$service/server/Dockerfile"
            if [ -f "$dockerfile" ]; then
              echo "âœ… æ‰¾åˆ° $service æœåŠ¡Dockerfile"
              # éªŒè¯Dockerfileè¯­æ³•
              docker build --dry-run -f "$dockerfile" . > /dev/null 2>&1 || {
                echo "âŒ $service æœåŠ¡Dockerfileè¯­æ³•é”™è¯¯"
                exit 1
              }
            else
              echo "âš ï¸ æœªæ‰¾åˆ° $service æœåŠ¡Dockerfile: $dockerfile"
            fi
          done

          # æ£€æŸ¥å‰ç«¯åº”ç”¨çš„Dockerfile
          for app in admin miniapp; do
            dockerfile="apps/$service/$app/Dockerfile"
            if [ -f "$dockerfile" ]; then
              echo "âœ… æ‰¾åˆ° $app åº”ç”¨Dockerfile"
              docker build --dry-run -f "$dockerfile" . > /dev/null 2>&1 || {
                echo "âŒ $app åº”ç”¨Dockerfileè¯­æ³•é”™è¯¯"
                exit 1
              }
            else
              echo "âš ï¸ æœªæ‰¾åˆ° $app åº”ç”¨Dockerfile: $dockerfile"
            fi
          done

          # æ£€æŸ¥docker-composeé…ç½®
          if [ -f "docker-compose.$ENVIRONMENT.yml" ]; then
            echo "âœ… æ‰¾åˆ°docker-composeé…ç½®"
            docker-compose -f "docker-compose.$ENVIRONMENT.yml" config > /dev/null || {
              echo "âŒ docker-composeé…ç½®è¯­æ³•é”™è¯¯"
              exit 1
            }
          else
            echo "âš ï¸ æœªæ‰¾åˆ°docker-composeé…ç½®: docker-compose.$ENVIRONMENT.yml"
          fi

          # æ£€æŸ¥Kubernetesé…ç½®
          echo "â˜¸ï¸ æ£€æŸ¥Kubernetesé…ç½®..."

          if [ -d "k8s/$ENVIRONMENT" ]; then
            echo "âœ… æ‰¾åˆ°Kubernetesé…ç½®ç›®å½•"

            # å®‰è£…kubectlï¼ˆå¦‚æœéœ€è¦ï¼‰
            if ! command -v kubectl &> /dev/null; then
              curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
              chmod +x kubectl
              sudo mv kubectl /usr/local/bin/
            fi

            # éªŒè¯Kubernetesé…ç½®
            kubectl --dry-run=client apply -f "k8s/$ENVIRONMENT/" || {
              echo "âŒ Kubernetesé…ç½®éªŒè¯å¤±è´¥"
              exit 1
            }
            echo "âœ… Kubernetesé…ç½®éªŒè¯é€šè¿‡"
          else
            echo "âš ï¸ æœªæ‰¾åˆ°Kubernetesé…ç½®ç›®å½•: k8s/$ENVIRONMENT"
          fi

      - name: å®‰å…¨æ‰«æ
        env:
          ENVIRONMENT: ${{ matrix.environment }}
        run: |
          echo "ğŸ”’ è¿è¡Œ $ENVIRONMENT ç¯å¢ƒå®‰å…¨æ‰«æ..."

          # åˆ›å»ºå®‰å…¨æ‰«æè„šæœ¬
          cat > security-scan.py << 'EOF'
          import os
          import json
          import subprocess
          import sys
          from pathlib import Path

          def scan_docker_images():
              """æ‰«æDockeré•œåƒå®‰å…¨æ¼æ´"""
              print("ğŸ³ æ‰«æDockeré•œåƒå®‰å…¨æ¼æ´...")

              # å®‰è£…trivyï¼ˆå¦‚æœéœ€è¦ï¼‰
              subprocess.run([
                  'sudo', 'apt-get', 'update', '-qq'
              ], check=False)

              subprocess.run([
                  'sudo', 'apt-get', 'install', '-y', 'wget', 'apt-transport-https', 'gnupg', 'lsb-release'
              ], check=False)

              subprocess.run([
                  'wget', '-qO', '-', 'https://aquasecurity.github.io/trivy-repo/deb/public.key'
              ], stdout=subprocess.PIPE, check=False)

              # æ‰«æåŸºç¡€é•œåƒ
              base_images = [
                  'python:3.13-slim',
                  'node:24-alpine',
                  'nginx:alpine'
              ]

              vulnerabilities = []

              for image in base_images:
                  print(f"  æ‰«æé•œåƒ: {image}")
                  try:
                      result = subprocess.run([
                          'docker', 'run', '--rm',
                          'aquasec/trivy:latest',
                          'image', '--format', 'json',
                          '--severity', 'HIGH,CRITICAL',
                          image
                      ], capture_output=True, text=True, timeout=300)

                      if result.returncode == 0 and result.stdout:
                          scan_result = json.loads(result.stdout)
                          if scan_result.get('Results'):
                              for res in scan_result['Results']:
                                  if res.get('Vulnerabilities'):
                                      vulnerabilities.extend(res['Vulnerabilities'])
                  except Exception as e:
                      print(f"    âš ï¸ æ‰«æå¤±è´¥: {e}")

              return vulnerabilities

          def scan_dependencies():
              """æ‰«æä¾èµ–åŒ…å®‰å…¨æ¼æ´"""
              print("ğŸ“¦ æ‰«æä¾èµ–åŒ…å®‰å…¨æ¼æ´...")

              vulnerabilities = []

              # æ‰«æNode.jsä¾èµ–
              try:
                  result = subprocess.run([
                      'pnpm', 'audit', '--json'
                  ], capture_output=True, text=True, cwd='.')

                  if result.stdout:
                      audit_result = json.loads(result.stdout)
                      if audit_result.get('advisories'):
                          for advisory in audit_result['advisories'].values():
                              if advisory.get('severity') in ['high', 'critical']:
                                  vulnerabilities.append({
                                      'type': 'npm',
                                      'package': advisory.get('module_name'),
                                      'severity': advisory.get('severity'),
                                      'title': advisory.get('title'),
                                      'url': advisory.get('url')
                                  })
              except Exception as e:
                  print(f"    âš ï¸ Node.jsä¾èµ–æ‰«æå¤±è´¥: {e}")

              # æ‰«æPythonä¾èµ–
              for service in ['community', 'enterprise']:
                  requirements_file = f'apps/{service}/server/requirements.txt'
                  if Path(requirements_file).exists():
                      try:
                          result = subprocess.run([
                              'pip-audit', '--format', 'json',
                              '--requirement', requirements_file
                          ], capture_output=True, text=True)

                          if result.stdout:
                              audit_result = json.loads(result.stdout)
                              for vuln in audit_result:
                                  if vuln.get('severity') in ['high', 'critical']:
                                      vulnerabilities.append({
                                          'type': 'pip',
                                          'service': service,
                                          'package': vuln.get('package'),
                                          'severity': vuln.get('severity'),
                                          'title': vuln.get('title'),
                                          'id': vuln.get('id')
                                      })
                      except Exception as e:
                          print(f"    âš ï¸ {service}æœåŠ¡Pythonä¾èµ–æ‰«æå¤±è´¥: {e}")

              return vulnerabilities

          def scan_secrets():
              """æ‰«æä»£ç ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
              print("ğŸ” æ‰«æä»£ç ä¸­çš„æ•æ„Ÿä¿¡æ¯...")

              secrets = []

              # ä½¿ç”¨ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼æ‰«æ
              import re

              secret_patterns = [
                  (r'password\s*=\s*["\'][^"\'\r]{8,}["\']', 'hardcoded_password'),
                  (r'api[_-]?key\s*=\s*["\'][^"\'\r]{20,}["\']', 'api_key'),
                  (r'secret[_-]?key\s*=\s*["\'][^"\'\r]{20,}["\']', 'secret_key'),
                  (r'token\s*=\s*["\'][^"\'\r]{20,}["\']', 'token'),
                  (r'-----BEGIN [A-Z ]+-----', 'private_key')
              ]

              for root, dirs, files in os.walk('.'):
                  # è·³è¿‡ä¸éœ€è¦æ‰«æçš„ç›®å½•
                  dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'dist', 'build']]

                  for file in files:
                      if file.endswith(('.py', '.js', '.ts', '.jsx', '.tsx', '.env', '.yaml', '.yml')):
                          file_path = os.path.join(root, file)
                          try:
                              with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                  content = f.read()

                                  for pattern, secret_type in secret_patterns:
                                      matches = re.finditer(pattern, content, re.IGNORECASE)
                                      for match in matches:
                                          secrets.append({
                                              'file': file_path,
                                              'type': secret_type,
                                              'line': content[:match.start()].count('\n') + 1,
                                              'match': match.group()[:50] + '...' if len(match.group()) > 50 else match.group()
                                          })
                          except Exception as e:
                              continue

              return secrets

          def main():
              environment = os.environ.get('ENVIRONMENT', 'staging')

              print(f"ğŸ”’ å¼€å§‹ {environment} ç¯å¢ƒå®‰å…¨æ‰«æ...")

              # æ‰«æç»“æœ
              scan_results = {
                  'environment': environment,
                  'docker_vulnerabilities': [],
                  'dependency_vulnerabilities': [],
                  'secrets': []
              }

              # æ‰«æDockeré•œåƒ
              try:
                  scan_results['docker_vulnerabilities'] = scan_docker_images()
              except Exception as e:
                  print(f"âŒ Dockeré•œåƒæ‰«æå¤±è´¥: {e}")

              # æ‰«æä¾èµ–åŒ…
              try:
                  scan_results['dependency_vulnerabilities'] = scan_dependencies()
              except Exception as e:
                  print(f"âŒ ä¾èµ–åŒ…æ‰«æå¤±è´¥: {e}")

              # æ‰«ææ•æ„Ÿä¿¡æ¯
              try:
                  scan_results['secrets'] = scan_secrets()
              except Exception as e:
                  print(f"âŒ æ•æ„Ÿä¿¡æ¯æ‰«æå¤±è´¥: {e}")

              # ä¿å­˜æ‰«æç»“æœ
              os.makedirs('security-reports', exist_ok=True)
              report_file = f'security-reports/{environment}-security-scan.json'

              with open(report_file, 'w') as f:
                  json.dump(scan_results, f, indent=2)

              print(f"ğŸ“ å®‰å…¨æ‰«ææŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")

              # è¾“å‡ºæ‘˜è¦
              docker_high_critical = len([v for v in scan_results['docker_vulnerabilities'] if v.get('Severity') in ['HIGH', 'CRITICAL']])
              dep_high_critical = len([v for v in scan_results['dependency_vulnerabilities'] if v.get('severity') in ['high', 'critical']])
              secrets_count = len(scan_results['secrets'])

              print(f"\nğŸ“Š å®‰å…¨æ‰«ææ‘˜è¦:")
              print(f"  Dockeré«˜å±æ¼æ´: {docker_high_critical}")
              print(f"  ä¾èµ–åŒ…é«˜å±æ¼æ´: {dep_high_critical}")
              print(f"  æ•æ„Ÿä¿¡æ¯æ³„éœ²: {secrets_count}")

              # æ£€æŸ¥æ˜¯å¦æœ‰é˜»å¡æ€§å®‰å…¨é—®é¢˜
              if docker_high_critical > 10 or dep_high_critical > 5 or secrets_count > 0:
                  print(f"\nâŒ å‘ç°ä¸¥é‡å®‰å…¨é—®é¢˜ï¼Œå»ºè®®ä¿®å¤åå†éƒ¨ç½²")
                  if environment == 'production':
                      print(f"ğŸš« ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è¢«é˜»æ­¢")
                      sys.exit(1)
                  else:
                      print(f"âš ï¸ æµ‹è¯•ç¯å¢ƒå…è®¸éƒ¨ç½²ï¼Œä½†è¯·å°½å¿«ä¿®å¤")
              else:
                  print(f"\nâœ… å®‰å…¨æ‰«æé€šè¿‡")

          if __name__ == '__main__':
              main()
          EOF

          # å®‰è£…å®‰å…¨æ‰«æå·¥å…·
          pip install pip-audit

          # è¿è¡Œå®‰å…¨æ‰«æ
          python security-scan.py

      - name: éƒ¨ç½²å°±ç»ªæ£€æŸ¥
        env:
          ENVIRONMENT: ${{ matrix.environment }}
        run: |
          echo "âœ… è¿è¡Œ $ENVIRONMENT ç¯å¢ƒéƒ¨ç½²å°±ç»ªæ£€æŸ¥..."

          # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
          required_vars=()

          if [ "$ENVIRONMENT" = "production" ]; then
            required_vars=("PROD_DB_HOST" "PROD_REDIS_HOST" "PROD_SECRET_KEY")
          else
            required_vars=("STAGING_DB_HOST" "STAGING_REDIS_HOST" "STAGING_SECRET_KEY")
          fi

          missing_vars=()
          for var in "${required_vars[@]}"; do
            if [ -z "${!var}" ]; then
              missing_vars+=("$var")
            fi
          done

          if [ ${#missing_vars[@]} -gt 0 ]; then
            echo "âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: ${missing_vars[*]}"
            echo "deployment_ready=false" >> $GITHUB_OUTPUT
            exit 1
          fi

          # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€ï¼ˆå¦‚æœæ˜¯stagingç¯å¢ƒï¼‰
          if [ "$ENVIRONMENT" = "staging" ]; then
            echo "ğŸ¥ æ£€æŸ¥stagingç¯å¢ƒæœåŠ¡å¥åº·çŠ¶æ€..."

            # è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹stagingç¯å¢ƒçš„å¥åº·æ£€æŸ¥
            # curl -f https://staging.example.com/health || exit 1
          fi

          echo "deployment_ready=true" >> $GITHUB_OUTPUT
        id: deployment

      - name: è®¾ç½®éƒ¨ç½²URL
        env:
          ENVIRONMENT: ${{ matrix.environment }}
        run: |
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "url=https://phoenixcoder.com" >> $GITHUB_OUTPUT
          else
            echo "url=https://staging.phoenixcoder.com" >> $GITHUB_OUTPUT
          fi
        id: deploy-url

      - name: ä¸Šä¼ å®‰å…¨æ‰«ææŠ¥å‘Š
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-report-${{ matrix.environment }}
          path: security-reports/

      - name: é€šçŸ¥éƒ¨ç½²çŠ¶æ€
        env:
          ENVIRONMENT: ${{ matrix.environment }}
          DEPLOYMENT_READY: ${{ steps.deployment.outputs.deployment_ready }}
          DEPLOY_URL: ${{ steps.deploy-url.outputs.url }}
        run: |
          if [ "$DEPLOYMENT_READY" = "true" ]; then
            echo "ğŸš€ $ENVIRONMENT ç¯å¢ƒå·²å‡†å¤‡å¥½éƒ¨ç½²"
            echo "ğŸ“ éƒ¨ç½²åœ°å€: $DEPLOY_URL"

            # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„éƒ¨ç½²é€»è¾‘
            # ä¾‹å¦‚ï¼šè§¦å‘éƒ¨ç½²è„šæœ¬ã€è°ƒç”¨éƒ¨ç½²APIç­‰

            if [ "$ENVIRONMENT" = "production" ]; then
              echo "ğŸ‰ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‡†å¤‡å®Œæˆï¼"
            else
              echo "ğŸ§ª æµ‹è¯•ç¯å¢ƒéƒ¨ç½²å‡†å¤‡å®Œæˆï¼"
            fi
          else
            echo "âŒ $ENVIRONMENT ç¯å¢ƒéƒ¨ç½²æ£€æŸ¥å¤±è´¥"
            exit 1
          fi
