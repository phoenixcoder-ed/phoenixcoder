#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHub Actions CI/CD çŠ¶æ€æ£€æŸ¥è„šæœ¬
ç”¨äºç›‘æ§å’ŒéªŒè¯ CI/CD æµç¨‹çš„è¿è¡ŒçŠ¶æ€
"""

import os
import sys
import json
import time
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import argparse
from pathlib import Path


class GitHubActionsMonitor:
    """GitHub Actions ç›‘æ§å™¨"""
    
    def __init__(self, token: str, repo: str, owner: str):
        self.token = token
        self.repo = repo
        self.owner = owner
        self.base_url = "https://api.github.com"
        self.headers = {
            "Authorization": f"token {token}",
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "CI-Status-Check/1.0"
        }
        
    def get_workflow_runs(self, workflow_id: Optional[str] = None, 
                         branch: Optional[str] = None, 
                         limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–å·¥ä½œæµè¿è¡Œè®°å½•"""
        url = f"{self.base_url}/repos/{self.owner}/{self.repo}/actions/runs"
        params = {
            "per_page": limit,
            "status": "completed"
        }
        
        if workflow_id:
            params["workflow_id"] = workflow_id
        if branch:
            params["branch"] = branch
            
        try:
            response = requests.get(url, headers=self.headers, params=params)
            response.raise_for_status()
            return response.json().get("workflow_runs", [])
        except requests.RequestException as e:
            print(f"âŒ è·å–å·¥ä½œæµè¿è¡Œè®°å½•å¤±è´¥: {e}")
            return []
    
    def get_workflow_run_details(self, run_id: int) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµè¿è¡Œè¯¦æƒ…"""
        url = f"{self.base_url}/repos/{self.owner}/{self.repo}/actions/runs/{run_id}"
        
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"âŒ è·å–å·¥ä½œæµè¿è¡Œè¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    def get_workflow_run_jobs(self, run_id: int) -> List[Dict[str, Any]]:
        """è·å–å·¥ä½œæµè¿è¡Œçš„ä½œä¸šåˆ—è¡¨"""
        url = f"{self.base_url}/repos/{self.owner}/{self.repo}/actions/runs/{run_id}/jobs"
        
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json().get("jobs", [])
        except requests.RequestException as e:
            print(f"âŒ è·å–å·¥ä½œæµä½œä¸šåˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_workflow_artifacts(self, run_id: int) -> List[Dict[str, Any]]:
        """è·å–å·¥ä½œæµäº§ç‰©"""
        url = f"{self.base_url}/repos/{self.owner}/{self.repo}/actions/runs/{run_id}/artifacts"
        
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json().get("artifacts", [])
        except requests.RequestException as e:
            print(f"âŒ è·å–å·¥ä½œæµäº§ç‰©å¤±è´¥: {e}")
            return []
    
    def get_workflows(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å·¥ä½œæµ"""
        url = f"{self.base_url}/repos/{self.owner}/{self.repo}/actions/workflows"
        
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json().get("workflows", [])
        except requests.RequestException as e:
            print(f"âŒ è·å–å·¥ä½œæµåˆ—è¡¨å¤±è´¥: {e}")
            return []


class CIStatusChecker:
    """CI/CD çŠ¶æ€æ£€æŸ¥å™¨"""
    
    def __init__(self, monitor: GitHubActionsMonitor):
        self.monitor = monitor
        self.report_data = {
            "timestamp": datetime.now().isoformat(),
            "repository": f"{monitor.owner}/{monitor.repo}",
            "workflows": [],
            "summary": {},
            "recommendations": [],
            "badges": {}
        }
    
    def check_workflow_health(self, days: int = 7) -> Dict[str, Any]:
        """æ£€æŸ¥å·¥ä½œæµå¥åº·çŠ¶æ€"""
        print(f"ğŸ” æ£€æŸ¥è¿‡å» {days} å¤©çš„å·¥ä½œæµå¥åº·çŠ¶æ€...")
        
        # è·å–æ‰€æœ‰å·¥ä½œæµ
        workflows = self.monitor.get_workflows()
        
        workflow_health = {}
        
        for workflow in workflows:
            workflow_id = workflow["id"]
            workflow_name = workflow["name"]
            
            print(f"  ğŸ“‹ æ£€æŸ¥å·¥ä½œæµ: {workflow_name}")
            
            # è·å–æœ€è¿‘çš„è¿è¡Œè®°å½•
            runs = self.monitor.get_workflow_runs(
                workflow_id=workflow_id, 
                limit=20
            )
            
            # è¿‡æ»¤æœ€è¿‘å‡ å¤©çš„è¿è¡Œè®°å½•
            cutoff_date = datetime.now() - timedelta(days=days)
            recent_runs = [
                run for run in runs 
                if datetime.fromisoformat(run["created_at"].replace("Z", "+00:00")) > cutoff_date
            ]
            
            if not recent_runs:
                workflow_health[workflow_name] = {
                    "status": "inactive",
                    "total_runs": 0,
                    "success_rate": 0,
                    "avg_duration": 0,
                    "last_run": None,
                    "issues": ["å·¥ä½œæµåœ¨æŒ‡å®šæ—¶é—´å†…æ²¡æœ‰è¿è¡Œ"]
                }
                continue
            
            # è®¡ç®—æˆåŠŸç‡
            successful_runs = [run for run in recent_runs if run["conclusion"] == "success"]
            failed_runs = [run for run in recent_runs if run["conclusion"] == "failure"]
            cancelled_runs = [run for run in recent_runs if run["conclusion"] == "cancelled"]
            
            success_rate = len(successful_runs) / len(recent_runs) * 100 if recent_runs else 0
            
            # è®¡ç®—å¹³å‡æŒç»­æ—¶é—´
            durations = []
            for run in recent_runs:
                if run["created_at"] and run["updated_at"]:
                    created = datetime.fromisoformat(run["created_at"].replace("Z", "+00:00"))
                    updated = datetime.fromisoformat(run["updated_at"].replace("Z", "+00:00"))
                    duration = (updated - created).total_seconds()
                    durations.append(duration)
            
            avg_duration = sum(durations) / len(durations) if durations else 0
            
            # è¯†åˆ«é—®é¢˜
            issues = []
            if success_rate < 80:
                issues.append(f"æˆåŠŸç‡è¾ƒä½: {success_rate:.1f}%")
            if len(failed_runs) > 3:
                issues.append(f"å¤±è´¥æ¬¡æ•°è¿‡å¤š: {len(failed_runs)} æ¬¡")
            if avg_duration > 3600:  # è¶…è¿‡1å°æ—¶
                issues.append(f"å¹³å‡è¿è¡Œæ—¶é—´è¿‡é•¿: {avg_duration/60:.1f} åˆ†é’Ÿ")
            
            # æ£€æŸ¥æœ€è¿‘å¤±è´¥çš„è¿è¡Œ
            recent_failures = [run for run in recent_runs[:5] if run["conclusion"] == "failure"]
            if recent_failures:
                issues.append(f"æœ€è¿‘æœ‰ {len(recent_failures)} æ¬¡å¤±è´¥")
            
            workflow_health[workflow_name] = {
                "status": "healthy" if success_rate >= 80 and not issues else "warning" if success_rate >= 60 else "critical",
                "total_runs": len(recent_runs),
                "successful_runs": len(successful_runs),
                "failed_runs": len(failed_runs),
                "cancelled_runs": len(cancelled_runs),
                "success_rate": round(success_rate, 2),
                "avg_duration": round(avg_duration, 2),
                "avg_duration_minutes": round(avg_duration / 60, 2),
                "last_run": recent_runs[0] if recent_runs else None,
                "issues": issues,
                "recent_failures": recent_failures[:3]  # æœ€è¿‘3æ¬¡å¤±è´¥
            }
        
        return workflow_health
    
    def analyze_job_performance(self, run_id: int) -> Dict[str, Any]:
        """åˆ†æä½œä¸šæ€§èƒ½"""
        print(f"ğŸ“Š åˆ†æè¿è¡Œ {run_id} çš„ä½œä¸šæ€§èƒ½...")
        
        jobs = self.monitor.get_workflow_run_jobs(run_id)
        
        job_analysis = {
            "total_jobs": len(jobs),
            "successful_jobs": 0,
            "failed_jobs": 0,
            "cancelled_jobs": 0,
            "jobs": [],
            "bottlenecks": [],
            "recommendations": []
        }
        
        for job in jobs:
            job_duration = 0
            if job.get("started_at") and job.get("completed_at"):
                started = datetime.fromisoformat(job["started_at"].replace("Z", "+00:00"))
                completed = datetime.fromisoformat(job["completed_at"].replace("Z", "+00:00"))
                job_duration = (completed - started).total_seconds()
            
            job_info = {
                "name": job["name"],
                "status": job["status"],
                "conclusion": job["conclusion"],
                "duration_seconds": job_duration,
                "duration_minutes": round(job_duration / 60, 2),
                "runner_name": job.get("runner_name", "unknown"),
                "steps_count": len(job.get("steps", [])),
                "url": job["html_url"]
            }
            
            job_analysis["jobs"].append(job_info)
            
            # ç»Ÿè®¡ä½œä¸šçŠ¶æ€
            if job["conclusion"] == "success":
                job_analysis["successful_jobs"] += 1
            elif job["conclusion"] == "failure":
                job_analysis["failed_jobs"] += 1
            elif job["conclusion"] == "cancelled":
                job_analysis["cancelled_jobs"] += 1
            
            # è¯†åˆ«ç“¶é¢ˆ
            if job_duration > 1800:  # è¶…è¿‡30åˆ†é’Ÿ
                job_analysis["bottlenecks"].append({
                    "job": job["name"],
                    "duration_minutes": round(job_duration / 60, 2),
                    "issue": "è¿è¡Œæ—¶é—´è¿‡é•¿"
                })
        
        # ç”Ÿæˆå»ºè®®
        if job_analysis["bottlenecks"]:
            job_analysis["recommendations"].append(
                "è€ƒè™‘ä¼˜åŒ–é•¿æ—¶é—´è¿è¡Œçš„ä½œä¸šï¼Œä½¿ç”¨ç¼“å­˜æˆ–å¹¶è¡ŒåŒ–"
            )
        
        if job_analysis["failed_jobs"] > 0:
            job_analysis["recommendations"].append(
                "æ£€æŸ¥å¤±è´¥çš„ä½œä¸šæ—¥å¿—ï¼Œä¿®å¤ç›¸å…³é—®é¢˜"
            )
        
        return job_analysis
    
    def check_artifacts_and_reports(self, run_id: int) -> Dict[str, Any]:
        """æ£€æŸ¥äº§ç‰©å’ŒæŠ¥å‘Š"""
        print(f"ğŸ“¦ æ£€æŸ¥è¿è¡Œ {run_id} çš„äº§ç‰©å’ŒæŠ¥å‘Š...")
        
        artifacts = self.monitor.get_workflow_artifacts(run_id)
        
        artifact_analysis = {
            "total_artifacts": len(artifacts),
            "artifacts": [],
            "missing_reports": [],
            "recommendations": []
        }
        
        expected_artifacts = [
            "coverage-report",
            "build-artifacts",
            "security-report-staging",
            "security-report-production"
        ]
        
        found_artifacts = []
        
        for artifact in artifacts:
            artifact_info = {
                "name": artifact["name"],
                "size_bytes": artifact["size_in_bytes"],
                "size_mb": round(artifact["size_in_bytes"] / 1024 / 1024, 2),
                "created_at": artifact["created_at"],
                "expired": artifact["expired"],
                "download_url": artifact.get("archive_download_url")
            }
            
            artifact_analysis["artifacts"].append(artifact_info)
            found_artifacts.append(artifact["name"])
        
        # æ£€æŸ¥ç¼ºå¤±çš„æŠ¥å‘Š
        for expected in expected_artifacts:
            if not any(expected in name for name in found_artifacts):
                artifact_analysis["missing_reports"].append(expected)
        
        # ç”Ÿæˆå»ºè®®
        if artifact_analysis["missing_reports"]:
            artifact_analysis["recommendations"].append(
                f"ç¼ºå°‘é‡è¦æŠ¥å‘Š: {', '.join(artifact_analysis['missing_reports'])}"
            )
        
        # æ£€æŸ¥äº§ç‰©å¤§å°
        large_artifacts = [a for a in artifact_analysis["artifacts"] if a["size_mb"] > 100]
        if large_artifacts:
            artifact_analysis["recommendations"].append(
                f"å‘ç°å¤§å‹äº§ç‰© (>100MB): {', '.join([a['name'] for a in large_artifacts])}"
            )
        
        return artifact_analysis
    
    def generate_status_badges(self, workflow_health: Dict[str, Any]) -> Dict[str, str]:
        """ç”ŸæˆçŠ¶æ€å¾½ç« """
        print("ğŸ·ï¸ ç”ŸæˆçŠ¶æ€å¾½ç« ...")
        
        badges = {}
        
        # æ€»ä½“å¥åº·çŠ¶æ€å¾½ç« 
        healthy_workflows = sum(1 for w in workflow_health.values() if w["status"] == "healthy")
        total_workflows = len(workflow_health)
        
        if total_workflows == 0:
            overall_status = "unknown"
            overall_color = "lightgrey"
        elif healthy_workflows == total_workflows:
            overall_status = "passing"
            overall_color = "brightgreen"
        elif healthy_workflows >= total_workflows * 0.8:
            overall_status = "mostly-passing"
            overall_color = "yellow"
        else:
            overall_status = "failing"
            overall_color = "red"
        
        badges["overall"] = f"https://img.shields.io/badge/CI%2FCD-{overall_status}-{overall_color}"
        
        # ä¸ºæ¯ä¸ªå·¥ä½œæµç”Ÿæˆå¾½ç« 
        for workflow_name, health in workflow_health.items():
            status = health["status"]
            success_rate = health["success_rate"]
            
            if status == "healthy":
                color = "brightgreen"
                label = f"{success_rate:.0f}%25"
            elif status == "warning":
                color = "yellow"
                label = f"{success_rate:.0f}%25"
            elif status == "critical":
                color = "red"
                label = f"{success_rate:.0f}%25"
            else:  # inactive
                color = "lightgrey"
                label = "inactive"
            
            # æ¸…ç†å·¥ä½œæµåç§°ç”¨äºURL
            clean_name = workflow_name.replace(" ", "%20").replace("/", "%2F")
            badges[workflow_name] = f"https://img.shields.io/badge/{clean_name}-{label}-{color}"
        
        return badges
    
    def generate_detailed_report(self, workflow_health: Dict[str, Any], 
                               job_analysis: Optional[Dict[str, Any]] = None,
                               artifact_analysis: Optional[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        print("ğŸ“ ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š...")
        
        report = []
        report.append("# ğŸ” CI/CD æµç¨‹çŠ¶æ€æŠ¥å‘Š\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append(f"**ä»“åº“**: {self.monitor.owner}/{self.monitor.repo}\n")
        
        # æ€»ä½“çŠ¶æ€
        healthy_count = sum(1 for w in workflow_health.values() if w["status"] == "healthy")
        warning_count = sum(1 for w in workflow_health.values() if w["status"] == "warning")
        critical_count = sum(1 for w in workflow_health.values() if w["status"] == "critical")
        inactive_count = sum(1 for w in workflow_health.values() if w["status"] == "inactive")
        
        report.append("## ğŸ“Š æ€»ä½“çŠ¶æ€\n")
        report.append(f"- âœ… å¥åº·å·¥ä½œæµ: {healthy_count}")
        report.append(f"- âš ï¸ è­¦å‘Šå·¥ä½œæµ: {warning_count}")
        report.append(f"- âŒ ä¸¥é‡é—®é¢˜å·¥ä½œæµ: {critical_count}")
        report.append(f"- ğŸ’¤ éæ´»è·ƒå·¥ä½œæµ: {inactive_count}\n")
        
        # å·¥ä½œæµè¯¦æƒ…
        report.append("## ğŸ”§ å·¥ä½œæµè¯¦æƒ…\n")
        report.append("| å·¥ä½œæµ | çŠ¶æ€ | æˆåŠŸç‡ | è¿è¡Œæ¬¡æ•° | å¹³å‡æ—¶é•¿ | é—®é¢˜ |")
        report.append("|--------|------|--------|----------|----------|------|")
        
        for workflow_name, health in workflow_health.items():
            status_emoji = {
                "healthy": "âœ…",
                "warning": "âš ï¸",
                "critical": "âŒ",
                "inactive": "ğŸ’¤"
            }.get(health["status"], "â“")
            
            issues_text = "; ".join(health["issues"]) if health["issues"] else "æ— "
            
            report.append(
                f"| {workflow_name} | {status_emoji} {health['status']} | "
                f"{health['success_rate']:.1f}% | {health['total_runs']} | "
                f"{health['avg_duration_minutes']:.1f}min | {issues_text} |"
            )
        
        report.append("\n")
        
        # ä½œä¸šåˆ†æï¼ˆå¦‚æœæä¾›ï¼‰
        if job_analysis:
            report.append("## ğŸ“Š ä½œä¸šæ€§èƒ½åˆ†æ\n")
            report.append(f"- æ€»ä½œä¸šæ•°: {job_analysis['total_jobs']}")
            report.append(f"- æˆåŠŸä½œä¸š: {job_analysis['successful_jobs']}")
            report.append(f"- å¤±è´¥ä½œä¸š: {job_analysis['failed_jobs']}")
            report.append(f"- å–æ¶ˆä½œä¸š: {job_analysis['cancelled_jobs']}\n")
            
            if job_analysis["bottlenecks"]:
                report.append("### ğŸŒ æ€§èƒ½ç“¶é¢ˆ\n")
                for bottleneck in job_analysis["bottlenecks"]:
                    report.append(f"- **{bottleneck['job']}**: {bottleneck['duration_minutes']:.1f}åˆ†é’Ÿ - {bottleneck['issue']}")
                report.append("\n")
        
        # äº§ç‰©åˆ†æï¼ˆå¦‚æœæä¾›ï¼‰
        if artifact_analysis:
            report.append("## ğŸ“¦ äº§ç‰©å’ŒæŠ¥å‘Š\n")
            report.append(f"- æ€»äº§ç‰©æ•°: {artifact_analysis['total_artifacts']}\n")
            
            if artifact_analysis["missing_reports"]:
                report.append("### âŒ ç¼ºå¤±æŠ¥å‘Š\n")
                for missing in artifact_analysis["missing_reports"]:
                    report.append(f"- {missing}")
                report.append("\n")
        
        # å»ºè®®
        all_recommendations = []
        for health in workflow_health.values():
            if health["status"] != "healthy":
                all_recommendations.append(f"ä¿®å¤ {health.get('name', 'æœªçŸ¥')} å·¥ä½œæµçš„é—®é¢˜")
        
        if job_analysis and job_analysis["recommendations"]:
            all_recommendations.extend(job_analysis["recommendations"])
        
        if artifact_analysis and artifact_analysis["recommendations"]:
            all_recommendations.extend(artifact_analysis["recommendations"])
        
        if all_recommendations:
            report.append("## ğŸ’¡ å»ºè®®\n")
            for i, rec in enumerate(all_recommendations, 1):
                report.append(f"{i}. {rec}")
            report.append("\n")
        
        return "\n".join(report)
    
    def run_full_check(self, days: int = 7, latest_run_analysis: bool = True) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´æ£€æŸ¥"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„ CI/CD çŠ¶æ€æ£€æŸ¥...\n")
        
        # æ£€æŸ¥å·¥ä½œæµå¥åº·çŠ¶æ€
        workflow_health = self.check_workflow_health(days)
        
        # åˆ†ææœ€æ–°è¿è¡Œçš„ä½œä¸šæ€§èƒ½
        job_analysis = None
        artifact_analysis = None
        
        if latest_run_analysis:
            # è·å–æœ€æ–°çš„è¿è¡Œ
            latest_runs = self.monitor.get_workflow_runs(limit=1)
            if latest_runs:
                latest_run = latest_runs[0]
                run_id = latest_run["id"]
                
                print(f"\nğŸ“Š åˆ†ææœ€æ–°è¿è¡Œ (ID: {run_id})...")
                job_analysis = self.analyze_job_performance(run_id)
                artifact_analysis = self.check_artifacts_and_reports(run_id)
        
        # ç”Ÿæˆå¾½ç« 
        badges = self.generate_status_badges(workflow_health)
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        detailed_report = self.generate_detailed_report(
            workflow_health, job_analysis, artifact_analysis
        )
        
        # æ±‡æ€»ç»“æœ
        self.report_data.update({
            "workflows": workflow_health,
            "job_analysis": job_analysis,
            "artifact_analysis": artifact_analysis,
            "badges": badges,
            "detailed_report": detailed_report,
            "summary": {
                "total_workflows": len(workflow_health),
                "healthy_workflows": sum(1 for w in workflow_health.values() if w["status"] == "healthy"),
                "warning_workflows": sum(1 for w in workflow_health.values() if w["status"] == "warning"),
                "critical_workflows": sum(1 for w in workflow_health.values() if w["status"] == "critical"),
                "inactive_workflows": sum(1 for w in workflow_health.values() if w["status"] == "inactive")
            }
        })
        
        return self.report_data
    
    def save_report(self, output_dir: str = "ci-reports") -> None:
        """ä¿å­˜æŠ¥å‘Š"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ä¿å­˜JSONæŠ¥å‘Š
        json_file = output_path / "ci-status-report.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(self.report_data, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        md_file = output_path / "ci-status-report.md"
        with open(md_file, "w", encoding="utf-8") as f:
            f.write(self.report_data["detailed_report"])
        
        # ä¿å­˜å¾½ç« ä¿¡æ¯
        badges_file = output_path / "badges.json"
        with open(badges_file, "w", encoding="utf-8") as f:
            json.dump(self.report_data["badges"], f, indent=2)
        
        print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ° {output_dir}/")
        print(f"  - JSONæŠ¥å‘Š: {json_file}")
        print(f"  - MarkdownæŠ¥å‘Š: {md_file}")
        print(f"  - å¾½ç« ä¿¡æ¯: {badges_file}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="GitHub Actions CI/CD çŠ¶æ€æ£€æŸ¥")
    parser.add_argument("--token", required=True, help="GitHub Personal Access Token")
    parser.add_argument("--repo", required=True, help="ä»“åº“åç§°")
    parser.add_argument("--owner", required=True, help="ä»“åº“æ‰€æœ‰è€…")
    parser.add_argument("--days", type=int, default=7, help="æ£€æŸ¥å¤©æ•° (é»˜è®¤: 7)")
    parser.add_argument("--output", default="ci-reports", help="è¾“å‡ºç›®å½• (é»˜è®¤: ci-reports)")
    parser.add_argument("--no-job-analysis", action="store_true", help="è·³è¿‡ä½œä¸šåˆ†æ")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = GitHubActionsMonitor(args.token, args.repo, args.owner)
    
    # åˆ›å»ºæ£€æŸ¥å™¨
    checker = CIStatusChecker(monitor)
    
    try:
        # è¿è¡Œå®Œæ•´æ£€æŸ¥
        report = checker.run_full_check(
            days=args.days, 
            latest_run_analysis=not args.no_job_analysis
        )
        
        # ä¿å­˜æŠ¥å‘Š
        checker.save_report(args.output)
        
        # è¾“å‡ºæ‘˜è¦
        summary = report["summary"]
        print("\n" + "="*50)
        print("ğŸ“Š CI/CD çŠ¶æ€æ£€æŸ¥æ‘˜è¦")
        print("="*50)
        print(f"æ€»å·¥ä½œæµæ•°: {summary['total_workflows']}")
        print(f"å¥åº·å·¥ä½œæµ: {summary['healthy_workflows']} âœ…")
        print(f"è­¦å‘Šå·¥ä½œæµ: {summary['warning_workflows']} âš ï¸")
        print(f"ä¸¥é‡é—®é¢˜å·¥ä½œæµ: {summary['critical_workflows']} âŒ")
        print(f"éæ´»è·ƒå·¥ä½œæµ: {summary['inactive_workflows']} ğŸ’¤")
        
        # æ˜¾ç¤ºå¾½ç« 
        print("\nğŸ·ï¸ çŠ¶æ€å¾½ç« :")
        for name, url in report["badges"].items():
            print(f"  {name}: {url}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡é—®é¢˜
        if summary['critical_workflows'] > 0:
            print("\nâŒ å‘ç°ä¸¥é‡é—®é¢˜ï¼Œè¯·æ£€æŸ¥è¯¦ç»†æŠ¥å‘Š")
            sys.exit(1)
        elif summary['warning_workflows'] > 0:
            print("\nâš ï¸ å‘ç°è­¦å‘Šï¼Œå»ºè®®æ£€æŸ¥è¯¦ç»†æŠ¥å‘Š")
            sys.exit(0)
        else:
            print("\nâœ… æ‰€æœ‰å·¥ä½œæµè¿è¡Œæ­£å¸¸")
            sys.exit(0)
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()