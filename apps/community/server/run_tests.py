#!/usr/bin/env python3
"""
æ™ºèƒ½æµ‹è¯•è¿è¡Œè„šæœ¬
æä¾›ä¾¿æ·çš„æµ‹è¯•æ‰§è¡Œå‘½ä»¤å’Œæµ‹è¯•ç­–ç•¥
"""

import os
import sys
import time
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# æ·»åŠ testsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "tests"))

from tests.pytest_config import IntelligentTestRunner, TestLevel


class TestReportGenerator:
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.reports_dir = project_root / "test-reports"
        self.reports_dir.mkdir(exist_ok=True)
    
    def generate_summary_report(self, results: Dict[str, int]) -> str:
        """ç”Ÿæˆæµ‹è¯•ç»“æœæ±‡æ€»æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = f"""
# æµ‹è¯•æ‰§è¡ŒæŠ¥å‘Š

**æ‰§è¡Œæ—¶é—´**: {timestamp}

## æµ‹è¯•ç»“æœæ±‡æ€»

| æµ‹è¯•ç±»å‹ | çŠ¶æ€ | é€€å‡ºç  |
|---------|------|--------|
"""
        
        total_tests = len(results)
        passed_tests = sum(1 for code in results.values() if code == 0)
        
        for test_type, exit_code in results.items():
            status = "âœ… é€šè¿‡" if exit_code == 0 else "âŒ å¤±è´¥"
            report += f"| {test_type.upper()} | {status} | {exit_code} |\n"
        
        report += f"""

## ç»Ÿè®¡ä¿¡æ¯

- **æ€»æµ‹è¯•å¥—ä»¶**: {total_tests}
- **é€šè¿‡å¥—ä»¶**: {passed_tests}
- **å¤±è´¥å¥—ä»¶**: {total_tests - passed_tests}
- **æˆåŠŸç‡**: {(passed_tests / total_tests * 100):.1f}%

## è¯¦ç»†æŠ¥å‘Š

- HTMLæŠ¥å‘Š: `test-report.html`
- è¦†ç›–ç‡æŠ¥å‘Š: `htmlcov/index.html`
- JSONæŠ¥å‘Š: `test-report.json`
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.reports_dir / f"test-summary-{datetime.now().strftime('%Y%m%d-%H%M%S')}.md"
        report_file.write_text(report, encoding='utf-8')
        
        return str(report_file)
    
    def parse_coverage_report(self) -> Optional[Dict]:
        """è§£æè¦†ç›–ç‡æŠ¥å‘Š"""
        coverage_file = self.project_root / "coverage.xml"
        if not coverage_file.exists():
            return None
        
        try:
            import xml.etree.ElementTree as ET
            tree = ET.parse(coverage_file)
            root = tree.getroot()
            
            coverage_data = {
                "line_rate": float(root.get("line-rate", 0)) * 100,
                "branch_rate": float(root.get("branch-rate", 0)) * 100,
                "lines_covered": int(root.get("lines-covered", 0)),
                "lines_valid": int(root.get("lines-valid", 0)),
                "branches_covered": int(root.get("branches-covered", 0)),
                "branches_valid": int(root.get("branches-valid", 0))
            }
            
            return coverage_data
        except Exception as e:
            print(f"è§£æè¦†ç›–ç‡æŠ¥å‘Šå¤±è´¥: {e}")
            return None


class TestEnvironmentManager:
    """æµ‹è¯•ç¯å¢ƒç®¡ç†å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
    
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        test_env = {
            "ENVIRONMENT": "test",
            "DATABASE_URL": "sqlite:///test.db",
            "REDIS_URL": "redis://localhost:6379/1",
            "JWT_SECRET_KEY": "test-secret-key",
            "LOG_LEVEL": "WARNING",
            "TESTING": "true"
        }
        
        for key, value in test_env.items():
            os.environ[key] = value
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        dirs_to_create = [
            "tests/logs",
            "test-reports",
            "htmlcov"
        ]
        
        for dir_path in dirs_to_create:
            (self.project_root / dir_path).mkdir(parents=True, exist_ok=True)
        
        print("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    def cleanup_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®åº“
        test_db = self.project_root / "test.db"
        if test_db.exists():
            test_db.unlink()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        temp_files = [
            ".coverage",
            "test-report.json",
            "test-report.html"
        ]
        
        for file_path in temp_files:
            file_obj = self.project_root / file_path
            if file_obj.exists():
                file_obj.unlink()
        
        print("âœ… æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")


def run_quick_tests():
    """è¿è¡Œå¿«é€Ÿæµ‹è¯• (å•å…ƒæµ‹è¯•)"""
    print("ğŸš€ è¿è¡Œå¿«é€Ÿæµ‹è¯• (å•å…ƒæµ‹è¯•)...")
    runner = IntelligentTestRunner()
    return runner.run_smart_tests("unit")


def run_changed_tests():
    """è¿è¡Œå˜æ›´ç›¸å…³çš„æµ‹è¯•"""
    print("ğŸ” è¿è¡Œå˜æ›´ç›¸å…³çš„æµ‹è¯•...")
    runner = IntelligentTestRunner()
    return runner.run_smart_tests("unit", changed_only=True)


def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•...")
    runner = IntelligentTestRunner()
    return runner.run_smart_tests("integration")


def run_full_test_suite():
    """è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶"""
    print("ğŸ¯ è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶...")
    
    project_root = Path.cwd()
    env_manager = TestEnvironmentManager(project_root)
    report_generator = TestReportGenerator(project_root)
    runner = IntelligentTestRunner(project_root)
    
    # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
    env_manager.setup_test_environment()
    
    start_time = time.time()
    
    try:
        # è¿è¡Œæµ‹è¯•å¥—ä»¶
        results = runner.run_test_suite(["unit", "integration"])
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = report_generator.generate_summary_report(results)
        
        # è§£æè¦†ç›–ç‡
        coverage_data = report_generator.parse_coverage_report()
        if coverage_data:
            print(f"\nğŸ“Š ä»£ç è¦†ç›–ç‡: {coverage_data['line_rate']:.1f}%")
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"\nâ±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {duration:.2f}ç§’")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡
        all_passed = all(code == 0 for code in results.values())
        return 0 if all_passed else 1
        
    finally:
        # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        env_manager.cleanup_test_environment()


def run_performance_tests():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•...")
    runner = IntelligentTestRunner()
    return runner.run_smart_tests("performance")


def run_security_tests():
    """è¿è¡Œå®‰å…¨æµ‹è¯•"""
    print("ğŸ”’ è¿è¡Œå®‰å…¨æµ‹è¯•...")
    runner = IntelligentTestRunner()
    return runner.run_smart_tests("security")


def install_test_dependencies():
    """å®‰è£…æµ‹è¯•ä¾èµ–"""
    print("ğŸ“¦ å®‰è£…æµ‹è¯•ä¾èµ–...")
    
    try:
        subprocess.run(
            [sys.executable, "-m", "pip", "install", "-r", "requirements.txt"],
            check=True
        )
        print("âœ… æµ‹è¯•ä¾èµ–å®‰è£…å®Œæˆ")
        return 0
    except subprocess.CalledProcessError as e:
        print(f"âŒ æµ‹è¯•ä¾èµ–å®‰è£…å¤±è´¥: {e}")
        return 1


def show_test_status():
    """æ˜¾ç¤ºæµ‹è¯•çŠ¶æ€"""
    print("ğŸ“‹ æµ‹è¯•çŠ¶æ€æ¦‚è§ˆ")
    print("="*50)
    
    project_root = Path.cwd()
    
    # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ•°é‡
    test_files = list(project_root.glob("tests/**/test_*.py"))
    print(f"æµ‹è¯•æ–‡ä»¶æ•°é‡: {len(test_files)}")
    
    # æ£€æŸ¥è¦†ç›–ç‡æŠ¥å‘Š
    coverage_file = project_root / "htmlcov" / "index.html"
    if coverage_file.exists():
        print(f"è¦†ç›–ç‡æŠ¥å‘Š: {coverage_file}")
    else:
        print("è¦†ç›–ç‡æŠ¥å‘Š: æœªç”Ÿæˆ")
    
    # æ£€æŸ¥æœ€æ–°æµ‹è¯•æŠ¥å‘Š
    reports_dir = project_root / "test-reports"
    if reports_dir.exists():
        reports = list(reports_dir.glob("test-summary-*.md"))
        if reports:
            latest_report = max(reports, key=lambda p: p.stat().st_mtime)
            print(f"æœ€æ–°æµ‹è¯•æŠ¥å‘Š: {latest_report}")
        else:
            print("æµ‹è¯•æŠ¥å‘Š: æœªç”Ÿæˆ")
    else:
        print("æµ‹è¯•æŠ¥å‘Š: æœªç”Ÿæˆ")
    
    print("="*50)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="PhoenixCoder æ™ºèƒ½æµ‹è¯•è¿è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python run_tests.py quick          # è¿è¡Œå¿«é€Ÿæµ‹è¯•
  python run_tests.py changed        # è¿è¡Œå˜æ›´ç›¸å…³æµ‹è¯•
  python run_tests.py integration    # è¿è¡Œé›†æˆæµ‹è¯•
  python run_tests.py full           # è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
  python run_tests.py performance    # è¿è¡Œæ€§èƒ½æµ‹è¯•
  python run_tests.py security       # è¿è¡Œå®‰å…¨æµ‹è¯•
  python run_tests.py install        # å®‰è£…æµ‹è¯•ä¾èµ–
  python run_tests.py status         # æ˜¾ç¤ºæµ‹è¯•çŠ¶æ€
"""
    )
    
    parser.add_argument(
        "command",
        choices=[
            "quick", "changed", "integration", "full", 
            "performance", "security", "install", "status"
        ],
        help="æµ‹è¯•å‘½ä»¤"
    )
    
    args = parser.parse_args()
    
    # å‘½ä»¤æ˜ å°„
    commands = {
        "quick": run_quick_tests,
        "changed": run_changed_tests,
        "integration": run_integration_tests,
        "full": run_full_test_suite,
        "performance": run_performance_tests,
        "security": run_security_tests,
        "install": install_test_dependencies,
        "status": show_test_status
    }
    
    command_func = commands[args.command]
    
    if args.command == "status":
        command_func()
        return 0
    else:
        return command_func()


if __name__ == "__main__":
    sys.exit(main())